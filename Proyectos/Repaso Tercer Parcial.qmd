---
title: "Repaso Tercer Parcial"
author: "Yuberley Cruz Caycedo"
date: "2024-06-22"
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: left
    number-sections: false
    highlight: tango
    include-in-header:
      text: |
        <style>
          body {
            font-family: "Times New Roman", Times, serif;
            line-height: 1.5;
            margin-left: 2cm;
            margin-right: 2cm;
          }
        </style>
---
## Serie de Tiempo

Una serie de tiempo es una secuencia de datos recogidos y ordenados en intervalos de tiempo regulares. Estos datos pueden representar cualquier tipo de variable econ√≥mica, como precios de acciones, producto interno bruto (PIB), tasas de desempleo, entre otros.

$$Y_t, Y_ {t-1}, Y_{t-2}, ‚Ä¶ Y_{t-k}, Y_{t+1}, Y_{t+2}, ‚Ä¶ Y_{t+h}$$

-   Serie estoc√°stica: una parte conocida (sistem√°tica) susceptible de predecir y de una parte totalmente desconocida (aleatoria)

-   Serie determin√≠stica: el futuro se puede predecir sin error Es una variable que est√° determinada o fija y que no cambia de una muestra a otra

### Componentes de una Serie de Tiempo

Las series de tiempo pueden descomponerse en varios componentes fundamentales:

1.  **Tendencia (T)**: Movimiento general y a largo plazo en los datos.

![Serie con tendencia](Serie%20de%20Tiempo%20con%20Tendencia.png){withd="100%"}

2.  Estacionalidad (S): Patrones repetitivos y predecibles en los datos dentro de un a√±o o cualquier per√≠odo fijo.

![Serie con Estacionalidad](Serie%20de%20Tiempo%20Estacional.png){withd="100%"}

3.  Ciclo (C): Fluctuaciones que ocurren en el largo plazo, relacionadas con el ciclo econ√≥mico.

![Serie con tendencia](Serie%20de%20Tiempo%20Ciclica.png){withd="100%"}

4.  Componentes Aleatorios (E): Variaciones irregulares y no predecibles en los datos.

![Serie con aleatoria](Serie%20de%20Tiempo%20Irregular.png){withd="100%"}

#### Ejemplos

##### Ejemplo 1: Tendencia

Si analizamos el PIB de un pa√≠s durante 20 a√±os, podr√≠amos observar una tendencia ascendente debido al crecimiento econ√≥mico sostenido.

##### Ejemplo 2: Estacionalidad

Las ventas de ropa pueden mostrar estacionalidad, con picos en invierno y verano, y bajas en primavera y oto√±o.

##### Ejemplo 3: Ciclo

La econom√≠a puede experimentar ciclos de auge y recesi√≥n que duran varios a√±os, reflejando per√≠odos de expansi√≥n y contracci√≥n.

##### Ejemplo 4: Componentes Aleatorios

Un evento inesperado, como un desastre natural, puede introducir fluctuaciones aleatorias en una serie de tiempo de precios de productos agr√≠colas.

### Cuadros Comparativos

#### Componentes de Series de Tiempo

| Componente         | Descripci√≥n                              | Ejemplo                                           |
|------------------|-------------------------|-----------------------------|
| Tendencia (T)      | Movimiento general a largo plazo         | Crecimiento del PIB a lo largo de las d√©cadas     |
| Estacionalidad (S) | Patrones repetitivos en per√≠odos fijos   | Ventas de helados m√°s altas en verano             |
| Ciclo (C)          | Fluctuaciones de largo plazo             | Ciclos econ√≥micos de expansi√≥n y recesi√≥n         |
| Aleatorio (E)      | Variaciones irregulares y no predecibles | Impacto de un terremoto en la producci√≥n agr√≠cola |

## Modelos de Regresi√≥n para Series de Tiempo

#### Conceptos Clave

1.  **Autocorrelaci√≥n**

    -   Definici√≥n: La autocorrelaci√≥n es la correlaci√≥n de una serie de tiempo con sus propios valores rezagados. Esto significa que los valores anteriores de la serie pueden influir en los valores futuros.

        -   Ejemplo: Si el precio de una acci√≥n hoy depende del precio de la acci√≥n en d√≠as anteriores, estamos viendo autocorrelaci√≥n.

La correlaci√≥n indica dos aspectos:

-   El valor indica la magnitud de la asociaci√≥n (-1 y 1)

-   El signo indica la direcci√≥n de la relaci√≥n

Negativa: cuando los valores de $t$ aumentan los de $t+k$ disminuyen

Cero: No hay relaci√≥n arm√≥nica en como los valores de $t$ y $t+k$ cambian

Positiva: cuando los valores de $t$ aumentan, los valores de $t+k$ tambi√©n aumentan

$$r_{k}= \frac{\sum_{t=1}^{n-k}(Y_{t}-\bar{Y})(Y_{t+k}-\bar{Y})}{\sum_{t=1}^{n}(Y_{t}-\bar{Y})^{2}}= \frac{Cov_{k}}{S^{2}}$$

2.  **Modelo Autorregresivo (AR)**

    -   **Definici√≥n**: Un modelo autorregresivo usa los valores pasados de la variable dependiente para predecir su valor futuro. Se denota como AR(p), donde p es el n√∫mero de rezagos.

    -   **Ecuaci√≥n**: $$Y_t = \phi_0 + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + ... + \phi_p Y_{t-p} + \epsilon_t$$‚Äã

    -   **Ejemplo**: Un AR(1) para el PIB puede ser $PIB_t = \phi_0 + \phi_1 PIB_{t-1} + \epsilon_t$.

3.  **Modelo de Media M√≥vil (MA)**

    -   **Definici√≥n**: Un modelo de media m√≥vil utiliza los errores pasados para predecir el valor futuro de la variable dependiente. Se denota como MA(q), donde q es el n√∫mero de rezagos de los errores.

    -   **Ecuaci√≥n**: $$Y_t = \mu + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + ... + \theta_q \epsilon_{t-q} + \epsilon_t$$‚Äã‚Äã

    -   **Ejemplo**: Un MA(1) para las tasas de inflaci√≥n puede ser $$\text{Inflaci√≥n}_t = \mu + \theta_1 \epsilon_{t-1} + \epsilon_t$$.

4.  **Modelo Autorregresivo de Media M√≥vil (ARMA)**

    -   **Definici√≥n**: Combina los modelos AR y MA para capturar tanto la autocorrelaci√≥n como las relaciones de media m√≥vil en una serie de tiempo. Se denota como ARMA(p,q).

    -   **Ecuaci√≥n**: $$Y_t = \phi_0 + \phi_1 Y_{t-1} + ... + \phi_p Y_{t-p} + \theta_1 \epsilon_{t-1} + ... + \theta_q \epsilon_{t-q} + \epsilon_t$$

#### **Ejemplos**

##### Ejemplo 1: Modelo AR(2)

Supongamos que estamos modelando el consumo de energ√≠a en funci√≥n de sus valores pasados: $$\text{Energ√≠a}_{t} = 0.5 + 0.6 \text{Energ√≠a}_{t-1} + 0.3 \text{Energ√≠a}_{t-2} + \epsilon_t$$‚Äã

##### Ejemplo 2: Modelo MA(1)

Si queremos modelar el √≠ndice de precios al consumidor (IPC) teniendo en cuenta el error del mes pasado: $$\text{IPC}_{t} = 2 + 0.8 \epsilon_{t-1} + \epsilon_{t}$$

##### Ejemplo 3: Modelo ARMA(1,1)

Para modelar el PIB considerando tanto el valor pasado del PIB como el error del per√≠odo anterior: $$PIB_t = 3 + 0.7 PIB_{t-1} + 0.5 \epsilon_{t-1} + \epsilon_t$$‚Äã

### Cuadro Comparativo de Modelos

| Modelo    | Ecuaci√≥n                                                                                           | Caracter√≠sticas                | Uso Principal                          |
|------------------|-------------------|------------------|------------------|
| AR(p)     | $$Y_t = \phi_0 + \sum_{i=1}^p \phi_i Y_{t-i} + \epsilon_t$$                                        | Captura autocorrelaci√≥n        | Series con fuerte dependencia temporal |
| MA(q)     | $$Y_t = \mu + \sum_{i=1}^q \theta_i \epsilon_{t-i} + \epsilon_t$$                                  | Captura dependencia en errores | Series con fluctuaciones irregulares   |
| ARMA(p,q) | $$Y_t = \phi_0 + \sum_{i=1}^p \phi_i Y_{t-i} + \sum_{j=1}^q \theta_j \epsilon_{t-j} + \epsilon_t$$ | Combina AR y MA                | Series con patrones complejos          |

## Conceptos Ampliados

#### Autocorrelaci√≥n y Funci√≥n de Autocorrelaci√≥n (ACF)

-   **Autocorrelaci√≥n**: La correlaci√≥n de una serie de tiempo con sus propios valores rezagados.

-   **Funci√≥n de Autocorrelaci√≥n (ACF)**: Mide la autocorrelaci√≥n de la serie de tiempo en diferentes rezagos. Ayuda a identificar patrones y a determinar la estructura del modelo ARMA.

#### Funci√≥n de Autocorrelaci√≥n Parcial (PACF)

-   **PACF**: Mide la correlaci√≥n entre la serie de tiempo y sus rezagos, eliminando el efecto de los rezagos intermedios. Es √∫til para identificar el orden p de un modelo AR(p).

![ACF Y ACFP](ACF%20y%20ACFP.png){withd="100%"}

#### Identificaci√≥n del Modelo

-   **ACF y PACF**: Usadas para determinar los √≥rdenes p y q de los modelos AR(p), MA(q) y ARMA(p,q).

    -   **AR(p)**: La PACF muestra un corte brusco despu√©s del rezago p.

    -   **MA(q)**: La ACF muestra un corte brusco despu√©s del rezago q.

    -   **ARMA(p,q)**: Tanto la ACF como la PACF decaen exponencialmente.

#### Estimaci√≥n de Par√°metros

-   **M√©todos**: M√°xima Verosimilitud y M√≠nimos Cuadrados.

-   **Desaf√≠os**: Complejidad debido a la dependencia temporal y problemas de no estacionariedad.

#### Diagn√≥stico del Modelo

-   **Residuales**: Deben comportarse como ruido blanco despu√©s del ajuste del modelo.

-   **Pruebas**: Ljung-Box para verificar si los residuales son ruido blanco.

#### Criterios de Selecci√≥n del Modelo

-   **AIC (Akaike Information Criterion)** y **BIC (Bayesian Information Criterion)**: Usados para seleccionar el modelo que mejor se ajusta a los datos, penalizando la complejidad del modelo.

#### Pron√≥sticos

-   **Metodolog√≠a**: Uso de modelos ajustados para predecir valores futuros.

-   **Evaluaci√≥n del Pron√≥stico**: M√©tricas como MSE (Mean Squared Error) y MAE (Mean Absolute Error) para evaluar la precisi√≥n de los pron√≥sticos.

### Resumen en Tabla

| Concepto                                  | Definici√≥n/Descripci√≥n                                                                | Uso Principal                             |
|-------------------|----------------------------------|-------------------|
| Autocorrelaci√≥n                           | Correlaci√≥n de una serie de tiempo con sus propios valores rezagados.                 | Identificaci√≥n de patrones temporales     |
| Funci√≥n de Autocorrelaci√≥n (ACF)          | Mide la autocorrelaci√≥n en diferentes rezagos.                                        | Determinaci√≥n de la estructura del modelo |
| Funci√≥n de Autocorrelaci√≥n Parcial (PACF) | Mide la correlaci√≥n entre la serie y sus rezagos, eliminando efectos intermedios.     | Identificaci√≥n del orden p en AR(p)       |
| Identificaci√≥n del Modelo                 | Uso de ACF y PACF para determinar los √≥rdenes p y q de AR(p), MA(q) y ARMA(p,q).      | Selecci√≥n de modelo adecuado              |
| Estimaci√≥n de Par√°metros                  | M√©todos de M√°xima Verosimilitud y M√≠nimos Cuadrados.                                  | Ajuste del modelo                         |
| Diagn√≥stico del Modelo                    | An√°lisis de residuales; uso de pruebas como Ljung-Box.                                | Verificaci√≥n de la adecuaci√≥n del modelo  |
| Criterios de Selecci√≥n del Modelo         | AIC y BIC para seleccionar el modelo que mejor se ajusta, penalizando la complejidad. | Optimizaci√≥n del modelo                   |
| Pron√≥sticos                               | Uso de modelos ajustados para predecir valores futuros; evaluaci√≥n con MSE y MAE.     | Predicci√≥n y evaluaci√≥n de precisi√≥n      |

## Estacionariedad y Pruebas de Ra√≠z Unitaria

#### Definici√≥n de Estacionariedad

-   **Serie Estacionaria**: Una serie de tiempo es estacionaria si sus propiedades estad√≠sticas, como la media, la varianza y la autocorrelaci√≥n, son constantes a lo largo del tiempo. Esto significa que los patrones de comportamiento de la serie no dependen del tiempo en que se observan.

-   **Serie No Estacionaria**: Una serie cuya media, varianza o autocorrelaci√≥n cambian con el tiempo. Estas series pueden tener tendencias, estacionalidades o varianzas que evolucionan con el tiempo.

#### Tipos de Estacionariedad

1.  **Estacionariedad Estricta**: Una serie de tiempo es estrictamente estacionaria si la distribuci√≥n conjunta de cualquier conjunto de valores de la serie es la misma independientemente del tiempo en que se observe.

2.  **Estacionariedad D√©bil (o Covarianza Estacionaria)**: Una serie es d√©bilmente estacionaria si la media, la varianza y la autocorrelaci√≥n son constantes a lo largo del tiempo.

#### Importancia de la Estacionariedad

-   **Modelado**: Los modelos ARMA (AutoRegressive Moving Average) requieren que las series sean estacionarias. Si la serie no es estacionaria, se deben aplicar transformaciones como la diferenciaci√≥n.

-   **Pron√≥sticos**: Las series estacionarias son m√°s predecibles, ya que sus propiedades no cambian con el tiempo.

### Pruebas de Ra√≠z Unitaria

#### Definici√≥n de Ra√≠z Unitaria

-   Una serie de tiempo tiene una ra√≠z unitaria si uno de los coeficientes del polinomio caracter√≠stico es igual a uno, lo que indica que la serie es no estacionaria. Esto implica que los efectos de un shock en la serie no se disipan con el tiempo y la serie sigue una caminata aleatoria.

#### Pruebas de Ra√≠z Unitaria

1.  **Prueba de Dickey-Fuller (DF)**

    -   **Objetivo**: Determinar si una serie de tiempo tiene una ra√≠z unitaria.

    -   **Hip√≥tesis**:

        -   $H_0$‚Äã: La serie tiene una ra√≠z unitaria (no estacionaria).

        -   $H_1$‚Äã: La serie no tiene una ra√≠z unitaria (estacionaria).

    -   **Proceso**: Ajuste del modelo $$ y_t = \alpha y_{t-1} + \epsilon_t$$. Si $\alpha = 0$, hay una ra√≠z unitaria.

2.  **Prueba de Dickey-Fuller Aumentada (ADF)**

    -   **Extensi√≥n**: Incluye t√©rminos rezagados adicionales para corregir la autocorrelaci√≥n en los errores.

    -   **Modelo**: $$\Delta y_t = \alpha y_{t-1} + \sum_{i=1}^p \beta_i \Delta y_{t-i} + \epsilon_t$$.

    -   **Importancia**: Es m√°s robusta que la prueba DF b√°sica porque maneja la autocorrelaci√≥n en los residuales, lo cual es crucial para obtener resultados confiables.

3.  **Prueba de Phillips-Perron (PP)**

    -   **Alternativa**: Similar a ADF, pero corrige la heterocedasticidad y autocorrelaci√≥n en los errores sin agregar t√©rminos rezagados.

    -   **M√©todo**: Utiliza estimadores no param√©tricos para ajustar las varianzas asint√≥ticas.

    -   **Ventaja**: Es √∫til en casos donde se sospecha de heterocedasticidad en los errores y es m√°s flexible que ADF en ciertos contextos.

### Conceptos Clave

#### Transformaciones para Estacionariedad

-   **Diferenciaci√≥n**: Aplicar la diferencia de primer orden ($\Delta y_t = y_t - y_{t-1}$) o de orden superior para eliminar tendencias. La diferenciaci√≥n puede convertir una serie no estacionaria en estacionaria.

-   **Transformaci√≥n Logar√≠tmica**: Usada para estabilizar la varianza en series que exhiben varianza no constante.

#### Componentes de una Serie No Estacionaria

1.  **Tendencia**: Componente determinista o estoc√°stico que aumenta o disminuye con el tiempo. Puede ser eliminada mediante diferenciaci√≥n o detrending.

2.  **Estacionalidad**: Componentes que se repiten a intervalos regulares, como anualmente, trimestralmente, etc. Puede ser ajustada utilizando t√©cnicas como desestacionalizaci√≥n.

3.  **Ciclo**: Fluctuaciones a largo plazo alrededor de una tendencia. Identificar los ciclos ayuda a entender los movimientos a largo plazo de la serie.

#### Importancia del Diagn√≥stico

-   **An√°lisis de Residuales**: Despu√©s de ajustar un modelo ARIMA, es crucial examinar los residuales para asegurarse de que se comportan como ruido blanco. Si no es as√≠, el modelo puede no ser adecuado.

-   **Pruebas de Diagn√≥stico**: Pruebas como Ljung-Box se utilizan para verificar la autocorrelaci√≥n en los residuales.

### Resumen en Tabla

| Concepto                         | Definici√≥n/Descripci√≥n                                                                 | Importancia/Aplicaci√≥n                    |
|:------------------|:---------------------------------|:------------------|
| **Serie Estacionaria**           | Serie con propiedades estad√≠sticas constantes a lo largo del tiempo.                   | Modelado y pron√≥sticos precisos.          |
| **Serie No Estacionaria**        | Serie con media, varianza o autocorrelaci√≥n cambiantes con el tiempo.                  | Requiere transformaciones.                |
| **Estacionariedad Estricta**     | Distribuci√≥n conjunta de valores de la serie es constante en el tiempo.                | An√°lisis te√≥rico.                         |
| **Estacionariedad D√©bil**        | Media, varianza y autocorrelaci√≥n son constantes en el tiempo.                         | Modelos ARMA.                             |
| **Ra√≠z Unitaria**                | Un coeficiente del polinomio caracter√≠stico es igual a uno; indica no estacionariedad. | Identificaci√≥n de no estacionariedad.     |
| **Prueba de Dickey-Fuller (DF)** | Prueba para detectar ra√≠z unitaria.                                                    | Identificaci√≥n de no estacionariedad.     |
| **Prueba de ADF**                | Extensi√≥n de DF con t√©rminos rezagados para autocorrelaci√≥n.                           | M√°s robusta que DF.                       |
| **Prueba de PP**                 | Corrige heterocedasticidad y autocorrelaci√≥n sin t√©rminos rezagados.                   | Alternativa a ADF.                        |
| **Diferenciaci√≥n**               | Transformaci√≥n para eliminar tendencias.                                               | Estacionarizaci√≥n de la serie.            |
| **Transformaci√≥n Logar√≠tmica**   | Usada para estabilizar la varianza.                                                    | Preprocesamiento de datos.                |
| **Tendencia**                    | Componente de la serie que aumenta o disminuye con el tiempo.                          | Identificaci√≥n de patrones.               |
| **Estacionalidad**               | Componentes que se repiten a intervalos regulares.                                     | An√°lisis de patrones recurrentes.         |
| **Ciclo**                        | Fluctuaciones a largo plazo alrededor de una tendencia.                                | An√°lisis de fluctuaciones de largo plazo. |
| **An√°lisis de Residuales**       | Verificaci√≥n de que los residuales de un modelo se comportan como ruido blanco.        | Validaci√≥n del modelo.                    |
| **Pruebas de Diagn√≥stico**       | Pruebas como Ljung-Box para verificar la autocorrelaci√≥n en los residuales.            | Verificaci√≥n de la idoneidad del modelo.  |

## Metodolog√≠a Box-Jenkins para Pronosticar Series de Tiempo

La metodolog√≠a Box-Jenkins es un enfoque sistem√°tico para identificar, estimar y verificar modelos ARIMA (AutoRegressive Integrated Moving Average) aplicables a series temporales estacionarias o no estacionarias. Este m√©todo, desarrollado por George Box y Gwilym Jenkins, sigue varios pasos: identificaci√≥n, estimaci√≥n, diagn√≥stico y pron√≥stico.

#### Pasos de la Metodolog√≠a Box-Jenkins:

1.  **Identificaci√≥n:**

    -   Determinar si la serie temporal es estacionaria o no.

    -   Usar gr√°ficos (como el correlograma) y pruebas estad√≠sticas (como la prueba de Dickey-Fuller) para verificar la estacionariedad.

    -   Identificar el orden del modelo ARIMA (p, d, q) utilizando el correlograma y el parciorregresograma.

2.  **Estaci√≥n de Modelos:**

    -   Seleccionar los valores iniciales de p, d y q basados en los gr√°ficos de autocorrelaci√≥n (ACF) y autocorrelaci√≥n parcial (PACF).

    -   Utilizar m√©todos de estimaci√≥n como M√°xima Verosimilitud para ajustar los par√°metros del modelo.

3.  **Diagn√≥stico:**

    -   Evaluar la adecuaci√≥n del modelo ajustado mediante el an√°lisis de los residuales.

    -   Utilizar pruebas estad√≠sticas como la prueba de Ljung-Box para verificar la ausencia de autocorrelaci√≥n en los residuales.

    -   Ajustar y refinar el modelo si los residuales no se comportan como ruido blanco.

4.  **Pron√≥stico:**

    -   Usar el modelo ajustado para realizar pron√≥sticos futuros.

    -   Evaluar la precisi√≥n de los pron√≥sticos y ajustar el modelo si es necesario.

#### Teor√≠a Matem√°tica:

-   **Modelo ARIMA(p,d,q):** Este modelo combina las partes AR (AutoRegresiva), I (Integrada) y MA (Media M√≥vil).

    $$Y_t = \phi_0 + \sum_{i=1}^{p} \phi_i Y_{t-i} + \sum_{i=1}^{q} \theta_i \epsilon_{t-i} + \epsilon_t$$

-   Donde:

    -   $Y_t$‚Äã es la serie temporal en el tiempo t.

    -   $\phi_i$‚Äã son los coeficientes del modelo AR.

    -   $\theta_i$‚Äã son los coeficientes del modelo MA.

    -   $\epsilon_t$ es el t√©rmino de error en el tiempo t.

    -   $p$ es el orden del modelo AR.

    -   $q$ es el orden del modelo MA.

    -   $d$ es el n√∫mero de diferenciaciones necesarias para hacer la serie estacionaria.

#### Tabla Resumen:

| Paso           | Descripci√≥n                                                                            | Herramientas/Pruebas                     |
|-------------------|----------------------------------|-------------------|
| Identificaci√≥n | Determinar estacionariedad y seleccionar orden inicial del modelo ARIMA.               | Correlograma, Prueba Dickey-Fuller       |
| Estimaci√≥n     | Ajustar los par√°metros del modelo utilizando m√©todos estad√≠sticos.                     | M√°xima Verosimilitud                     |
| Diagn√≥stico    | Verificar la adecuaci√≥n del modelo evaluando los residuales.                           | Prueba Ljung-Box, An√°lisis de Residuales |
| Pron√≥stico     | Utilizar el modelo ajustado para realizar predicciones futuras y evaluar su precisi√≥n. | Forecasting, Evaluaci√≥n de Pron√≥sticos   |

## Prueba de Cointegraci√≥n para Series de Tiempo

La prueba de cointegraci√≥n es utilizada para determinar si existe una relaci√≥n de equilibrio a largo plazo entre dos o m√°s series temporales no estacionarias. Conceptualmente, si dos o m√°s series temporales est√°n cointegradas, significa que aunque individualmente pueden ser no estacionarias, alguna combinaci√≥n lineal de ellas es estacionaria. Esta relaci√≥n de equilibrio a largo plazo es de inter√©s econ√≥mico y financiero.

#### Conceptual:

-   **Cointegraci√≥n:** Si dos series temporales $X_t$‚Äã e $Y_t$‚Äã son integradas de orden 1 (I(1)), y existe un coeficiente $\beta$ tal que la combinaci√≥n lineal $X_t - \beta Y_t$ es estacionaria (I(0)), entonces $X_t$‚Äã e $Y_t$‚Äã est√°n cointegradas.

#### Matem√°ticamente:

Para dos series temporales $X_t$‚Äã e $Y_t$‚Äã:

1.  Si $Xt‚Äã‚àºI(1)$ y $Y_t \sim I(1)$.

2.  Existe $\beta$ tal que $Z_t = X_t - \beta Y_t \sim I(0)$.

### M√©todos de Prueba de Cointegraci√≥n

#### 1. M√©todo de Engle y Granger:

El m√©todo de Engle y Granger se utiliza para probar la cointegraci√≥n entre dos series temporales.

1.  **Paso 1:** Realizar una regresi√≥n de $Y_t$‚Äã sobre $X_t$‚Äã:

    $$Y_t = \alpha + \beta X_t + \epsilon_t$$

2.  **Paso 2:** Obtener los residuos $\epsilon_t$‚Äã de la regresi√≥n.

3.  **Paso 3:** Aplicar una prueba de ra√≠z unitaria (como la prueba de Dickey-Fuller) a los residuos $\epsilon_t$‚Äã.

    -   Si los residuos $\epsilon_t$‚Äã son estacionarios, $Y_t$‚Äã y $X_t$‚Äã est√°n cointegrados.

#### 2. Prueba de Johansen:

La prueba de Johansen se utiliza para determinar el n√∫mero de vectores de cointegraci√≥n en un sistema de m√∫ltiples series temporales.

1.  **Modelo VAR:** Formar un modelo Vector Autoregresivo (VAR).

2.  **Modelo VECM:** Transformar el modelo VAR en un Modelo de Correcci√≥n de Errores Vectorial (VECM):

    $$\Delta Y_t = \Pi Y_{t-1} + \sum_{i=1}^{k-1} \Gamma_i \Delta Y_{t-i} + \epsilon_t$$

    Donde $\Pi$ y $\Gamma_i$ son matrices de par√°metros.

3.  **Test de Rango de la Matriz** $\Pi$: Evaluar el rango de la matriz $\Pi$ para determinar el n√∫mero de vectores de cointegraci√≥n.

    -   **Prueba Trace:** Eval√∫a el rango de $\Pi$ mediante la traza.

    -   **Prueba M√°ximo Eigenvalor:** Eval√∫a el mayor eigenvalor de $\Pi$.

#### 3. Prueba de Phillips-Ouliaris:

El m√©todo de Phillips-Ouliaris es una prueba de cointegraci√≥n residual similar al m√©todo de Engle y Granger, pero con ajustes para la no estacionariedad y la autocorrelaci√≥n en los residuos.

1.  **Regresi√≥n de Cointegraci√≥n:**

    -   Realizar una regresi√≥n entre las series temporales.

2.  **Residuos Ajustados:**

    -   Obtener los residuos y ajustar por autocorrelaci√≥n.

3.  **Prueba de Ra√≠z Unitaria:**

    -   Aplicar la prueba de ra√≠z unitaria ajustada a los residuos.

### Tabla Comparativa de M√©todos de Cointegraci√≥n

| Caracter√≠stica            | M√©todo de Engle y Granger                    | Prueba de Johansen                               | Prueba de Phillips-Ouliaris                            |
|------------------|------------------|------------------|-------------------|
| Series Temporales         | Bivariada (dos series)                       | Multivariada (m√°s de dos series)                 | Bivariada (dos series)                                 |
| Enfoque                   | Residual                                     | Vector Autoregresivo (VAR/VECM)                  | Residual                                               |
| Pasos Principales         | Regresi√≥n, Residuos, Prueba de Ra√≠z Unitaria | Modelo VAR, Transformaci√≥n VECM, Prueba de Rango | Regresi√≥n, Residuos Ajustados, Prueba de Ra√≠z Unitaria |
| Tipo de Prueba            | Prueba de Dickey-Fuller sobre residuos       | Prueba Trace y M√°ximo Eigenvalor                 | Prueba de ra√≠z unitaria ajustada                       |
| Considera Autocorrelaci√≥n | No expl√≠citamente                            | S√≠                                               | S√≠                                                     |
| Complejidad               | Relativamente Simple                         | M√°s Complejo                                     | Intermedio                                             |
| Aplicabilidad             | Dos series, an√°lisis sencillo                | M√∫ltiples series, an√°lisis avanzado              | Dos series, robusto a autocorrelaci√≥n                  |

## Modelo de Correci√≥n de Errores MCE

El modelo de correcci√≥n de errores me permite probar el equilibrio en el corto plazo sabiendo que existe un equilibrio en el largo plazo (demostrado a traves de una prueba de cointegracion). Por supuesto en el corto plazo, puede haber desequilibrio. En consecuencia puede tratarse el termino de error, como error de eqilibrio. Y se puede utilizar este termino de error para atar el comportamiento de corto plazo con el de largo plazo. El ECM corrige el desequilibrio. Engle y Granger (1987) establece una equivalencia entre los conceptos de cointegraci√≥n y modelo ECM, en cuanto cointegraci√≥n implica un modelo de ECM y a la vez un modelo de ECM implica cointegracion (teorema de representaci√≥n). para entenderlo consideremos dos series de tiempo escalares $Y_t$ y $X_t$, ambas $L(1)$. Un modelo autorregresivo distribuidos de rezagos (ADL) de orden (1, 1) de estas series es:

$$Y_t = \delta + \theta Y_{t-1} + \delta_0X_t + \delta_1X_{t-1} + \epsilon_t$$

donde:

$$\epsilon_t \overset{iid}{\sim} N(0,1)$$

$$\delta + \theta Y_{t-1}$$ = autoregresivo

$$\delta_0X_t + \delta_1X_{t-1}$$ = rezago distribuido

$$\epsilon_t$$ = termino de error

Se tiene que cumplir estas condiciones para encontrar la relaci√≥n de largo plazo

$$X \sim I(1)$$

$$Y \sim I(1)$$

$$\epsilon \sim I(0)$$

Pero pese a que $\epsilon_t$ sea estacionario, a√∫n puede presentar autocorrelaci√≥n. Una posible soluci√≥n es incluir t√©rminos rezagados para obtener residuos que no tengan autocorrelaci√≥n. Por ejemplo:

Introducimos en el ARDL

$$Y_t = Y_{t-1} = Y$$

$$X_t = X_{t-1} = X$$

$$\epsilon_t = 0$$

### Reparametrizaci√≥n de la Ecuaci√≥n ADL

Puedo reescribir el ARDL (1, 1)

$$Y = \delta + \theta_1 Y+ \delta_0X + \delta_1X$$

$$(1 - \theta_1) Y = \delta + (\delta_0 + \delta_1)X$$

$$Y = \frac{\delta}{(1 - \theta_1)} + \frac{(\delta_0 + \delta_1)}{(1 - \theta_1)}X$$

$$Y = \beta_1 + \beta_2X$$

Donde:

$$\beta_1 = \frac{\delta}{(1 - \theta_1)}$$

$$\beta_2 = \frac{(\delta_0 + \delta_1)}{(1 - \theta_1)}$$

La primera diferencia es un cambio del corto plazo

$$\Delta Y_t = Y_t - Y_{t-1}$$

$$\Delta X_t = X_t - X_{t-1}$$

Restar a ambos lados $Y_{t-1}$ y restando $\delta_0 X_{t-1}$ (manipulaci√≥n algebraica)

$$Y_t = \delta + \theta Y_{t-1} + \delta_0X_t + \delta_1X_{t-1} + \epsilon_t$$

$$Y_t - Y_{t-1} = \delta + \theta_1 Y_{t-1} - Y_{t-1} + \delta_0X_t + \delta_0 X_{t-1} -\delta_0 X_{t-1} + \theta_1X_{t-1} + \epsilon_t$$

$$\Delta Y_t = \delta + (\theta -1)Y_{t-1} + \delta_0(X_t - X_{t-1}) + (\delta_0 + \delta_1)X_{t-1} + \epsilon_t$$

$$\Delta Y_t = \delta + (\theta -1)Y_{t-1} + \delta_0 \Delta X_t + (\delta_0 + \delta_1)X_{t-1} + \epsilon_t$$

$$\Delta Y_t = [\delta + (\theta -1)Y_{t-1} + (\delta_0 + \delta_1)X_{t-1}] + \delta_0 \Delta X_t + \epsilon_t$$

Multiplicamos y dividimos por $(\theta -1)$ la expresion $[\delta + (\theta -1)Y_{t-1} + (\delta_0 + \delta_1)X_{t-1}]$, asi:

$$\Delta Y_t = (\theta -1)[\frac{\delta}{\theta -1)} + \frac{\theta -1}{\theta -1}Y_{t-1} + \frac{\delta_0 + \delta_1}{\theta-1}X_{t-1}] + \delta_0 \Delta X_t + \epsilon_t$$

Ahora $\theta-1 = -(1-\theta)$

$$\Delta Y_t = -(1-\theta)[\frac{\delta}{-(1-\theta)} + Y_{t-1} + \frac{\delta_0 + \delta_1}{-(1-\theta)}X_{t-1}] + \delta_0 \Delta X_t + \epsilon_t$$

Donde:

$$\frac{\delta}{(1-\theta)} = -\beta_1$$

$$\frac{\delta_0 + \delta_1}{(1-\theta)} = -\beta_2$$

$$\Delta Y_t = -(1-\theta)[-\beta_1 + Y_{t-1} - \beta_2X_{t-1}] + \delta_0 \Delta X_t + \epsilon_t$$

$$\Delta Y_t = -(1-\theta)[Y_{t-1}-\beta_1 -\beta_2X_{t-1}] + \delta_0 \Delta X_t + \epsilon_t$$

Recordemos que $Y_t = Y_{t-1} = Y$ , donde $\hat{Y} = \beta_1 + \beta_2X$

$\Delta Y_t = -(1-\theta)[Y_{t-1}-\hat Y_{t-1}] + \delta_0 \Delta X_t + \epsilon_t$ Se puede ver que: $Y_{t-1} - \hat{Y_{t-1}} = \epsilon_{t-1}$ , quedando la ecuacion de correci√≥n de errores

$$\Delta Y_t = -(1-\theta)\epsilon_{t-1} + \delta_0 \Delta X_t + \epsilon_t$$

$$\Delta Y_t = -\alpha \epsilon_{t-1} + \delta_0 \Delta X_t + \epsilon_t$$

Donde:

$$(1-\theta_1) = \delta_0$$

$$-(1-\theta) = -\alpha$$

$$\frac{\delta}{(1-\theta)} = -\beta_1$$

$$\frac{\delta_0 + \delta_1}{(1-\theta)} = -\beta_2$$

-   Se debe indicar que $\delta_0 \Delta X_t$ recoge la relacion de corto plazo donde, $(1-\theta_1) = \delta_0$ es un coeficiente de impacto, el cual mide los efectos de corto plazo de un cambio de $X_t$

-   $-\alpha \epsilon_{t-1}$, me recoge la relacion de largo plazo donde, $-(1-\theta) = -\alpha$ muestra la correcion de $\Delta Y_t$ respecto al error (desviaci√≥n del largo plazo) en ${t-1}$ (coeficiente de ajuste).

-   Si se da un $\epsilon_{t-1}$ positivo es porque $Y_{t-1}>\beta_1+\beta_2 X_{t-1}$, entonces $Y_t$ debe caer y $\Delta Y_{t-1}$ sera negativo (y viceversa).

-   si hay una relacion de cointegracion, siempre se daran ajustes que corrigen el error.

-   empiricamente debemos encontrar que $\delta_0 = 1- \theta_1 > 0$ , $\theta_1<0$ , ya que se demostraria que los cambios son hacia el equilibrio (modelovalido).

-   El t√©rmino $$-\alpha (Y_{t-1} - \beta_1 + \beta_2X_{t-1})$$

    -   tambi√©n se puede representar como $-\alpha(\epsilon_{t-1})$

    -   se conoce como el **mecanismo de correcci√≥n de errores**.

    Recuerda que $Y_{t} = \beta_1 + \beta_2X_{t}$ representa el equilibrio de largo plazo:

    -   si $\epsilon_t = Y_t - \beta_1 + \beta_2X_{t}~>~0, Y_t$ est√° sobre el punto de equilibrio en $t‚àí1$.

    -   si $\epsilon_t = Y_t - \beta_1 + \beta_2X_{t}~<~0, Y_t$est√° debajo el punto de equilibrio en $t‚àí1$.

Nota: El mecanismo de correcci√≥n de errores se refiere a la forma en que un sistema o proceso ajusta su comportamiento para volver a un estado de equilibrio. En el contexto de las ecuaciones presentadas, se hace referencia a c√≥mo la variable $Y_t$ se ajusta hacia el equilibrio representado por $\beta_1 + \beta_2X_{t}$ cuando la diferencia entre $Y_t ~y~ \beta_1 + \beta_2X_{t}$ es positiva $(\epsilon_t > 0 )$ o negativa $(\epsilon_t < 0)$. Si $(\epsilon_t > 0)$, significa que $Y_t$ est√° por encima del punto de equilibrio en $t-1$, mientras que si $(\epsilon_t < 0)$, significa que $Y_t$ est√° por debajo del punto de equilibrio en $t-1$. En ambos casos, el sistema tiende a corregir el error y volver al equilibrio de largo plazo.

#### Interpretaci√≥n de los Coeficientes

-   $\phi$ : Coeficiente de impacto a corto plazo, mide el efecto inmediato de un cambio en XXX.

-   $\psi$ : Coeficiente de ajuste, indica c√≥mo se corrige el desequilibrio a largo plazo.

-   $Y_{t-1} - \theta X_{t-1}$‚Äã: Error de equilibrio que el MCE corrige.

### Tabla Comparativa

| Caracter√≠stica          | Modelo ADL                                                                  | Modelo de Correcci√≥n de Errores (MCE)                                           |
|------------------|--------------------------|----------------------------|
| Ecuaci√≥n Base           | $$Y_t = \alpha + \beta X_t + \gamma Y_{t-1} + \delta X_{t-1} + \epsilon_t$$ | $$\Delta Y_t = \phi \Delta X_t + \psi (Y_{t-1} - \theta X_{t-1}) + \epsilon_t$$ |
| Objetivo                | Relaci√≥n entre variables con rezagos                                        | Correcci√≥n de desequilibrio a corto y largo plazo                               |
| Cointegraci√≥n           | No directamente considerado                                                 | Impl√≠cita, basada en el teorema de representaci√≥n                               |
| Desequilibrio           | No expl√≠citamente tratado                                                   | Corregido mediante el t√©rmino de error                                          |
| Coeficiente de Impacto  | $$\beta$$                                                                   | $$\phi$$                                                                        |
| Coeficiente de Ajuste   | No expl√≠cito                                                                | $$\psi$$                                                                        |
| Relaci√≥n de Largo Plazo | No considerado                                                              | $$Y_{t-1} - \theta X_{t-1}$$‚Äã                                                    |
| Primera Diferencia      | No aplicado                                                                 | S√≠, $\Delta Y_t$ y $\Delta X_t$                                                 |
| Estacionariedad         | Puede tener autocorrelaci√≥n                                                 | Se ajusta para lograr residuales no autocorrelacionados                         |

## **Modelos de Ecuaciones Simultaneas (MES)**

La estimaci√≥n en modelos de ecuaciones simult√°neas (MES) es esencial en econometr√≠a para modelar sistemas donde las variables end√≥genas influyen mutuamente. Este enfoque es vital para entender interacciones complejas en econom√≠a y otras ciencias sociales. Los modelos MES permiten la estimaci√≥n de par√°metros estructurales que reflejan relaciones causales directas entre las variables end√≥genas, diferenci√°ndolos de los par√°metros de la forma reducida que solo reflejan correlaciones observadas.

### **Identificaci√≥n**

La identificaci√≥n asegura que los par√°metros estructurales del modelo puedan estimarse de manera √∫nica. Esto es crucial porque, sin identificaci√≥n, no es posible distinguir entre diferentes conjuntos de par√°metros que generan los mismos resultados observables.

1.  **Condici√≥n de Orden**:

    -   **Definici√≥n 1**: En un modelo con MMM ecuaciones, una ecuaci√≥n est√° identificada si se excluyen al menos M‚àí1M-1M‚àí1 variables (end√≥genas y predeterminadas) del modelo.

    -   **Definici√≥n 2**: La ecuaci√≥n est√° identificada si el n√∫mero de variables predeterminadas excluidas (K‚àíkK-kK‚àík) es mayor o igual al n√∫mero de variables end√≥genas incluidas menos uno (m‚àí1m-1m‚àí1).

    -   **Interpretaci√≥n**:

        -   Si K‚àík=m‚àí1K-k = m-1K‚àík=m‚àí1, la ecuaci√≥n est√° exactamente identificada.

        -   Si K‚àík>m‚àí1K-k > m-1K‚àík\>m‚àí1, est√° sobreidentificada.

        -   Si K‚àík<m‚àí1K-k < m-1K‚àík\<m‚àí1, no est√° identificada.

2.  **Condici√≥n de Rango**:

    -   Una ecuaci√≥n est√° identificada si se puede construir al menos un determinante no nulo de orden (M‚àí1)(M-1)(M‚àí1) a partir de los coeficientes de variables excluidas de esa ecuaci√≥n, pero incluidas en otras ecuaciones del modelo.

    -   Esto garantiza que las variables excluidas aportan suficiente informaci√≥n para identificar los par√°metros estructurales de la ecuaci√≥n en cuesti√≥n.

### **M√©todos de Estimaci√≥n**

Existen varios m√©todos para estimar los par√°metros en modelos de ecuaciones simult√°neas, dependiendo de si las ecuaciones est√°n exactamente identificadas o sobreidentificadas.

1.  **M√©todo de M√≠nimos Cuadrados Indirectos (MCI)**:

    -   Se aplica cuando el modelo estructural est√° exactamente identificado.

    -   **Pasos**:

        1.  **Forma Reducida**: Convertir el sistema estructural en su forma reducida, donde cada variable end√≥gena se expresa en funci√≥n de todas las variables predeterminadas y los errores.

        2.  **Estimaci√≥n por MCO**: Aplicar m√≠nimos cuadrados ordinarios (MCO) a las ecuaciones de la forma reducida para obtener estimaciones de los par√°metros de la forma reducida.

        3.  **Derivaci√≥n de Par√°metros Estructurales**: Utilizar las relaciones entre los par√°metros estructurales y los par√°metros de la forma reducida para estimar los primeros a partir de los segundos.

2.  **M√©todo de M√≠nimos Cuadrados en Dos Etapas (MC2E)**:

    -   Se utiliza cuando una ecuaci√≥n est√° sobreidentificada.

    -   **Pasos**:

        1.  **Primera Etapa**: Regresi√≥n de las variables end√≥genas sobre todas las variables predeterminadas para obtener estimaciones libres de error de las variables end√≥genas.

        2.  **Segunda Etapa**: Sustituir las variables end√≥genas por sus valores estimados en la primera etapa y aplicar MCO a las ecuaciones modificadas para estimar los par√°metros estructurales.

#### Ejemplo Matem√°tico

#### Identificaci√≥n

Consideremos el siguiente sistema de ecuaciones:

1.  Demanda: $$Q_{t}^{d} = \alpha_0 + \alpha_1 P_t + \alpha_2 I_t + u_{t}^{d}$$

2.  Oferta: $$Q_t^s = \beta_0 + \beta_1 P_t + \beta_2 P_{t-1} + u_t^s$$

    **Condici√≥n de Orden**:

-   **Demanda**:

    -   N√∫mero de variables excluidas ($K-k$): 1 ($P_{t-1}$‚Äã).

    -   N√∫mero de variables end√≥genas menos uno ($m-1$): 1 ($P_t$‚Äã).

    -   **Conclusi√≥n**: Exactamente identificada ($K-k = m-1$).

-   **Oferta**:

    -   N√∫mero de variables excluidas ($K-k$): 1 ($I_t$‚Äã).

    -   N√∫mero de variables end√≥genas menos uno ($m-1$): 1 ($P_t$‚Äã).

    -   **Conclusi√≥n**: Exactamente identificada ($K-k = m-1$).

**Condici√≥n de Rango**:

-   Matriz de coeficientes de variables excluidas debe tener un determinante no nulo.

-   Para la ecuaci√≥n de demanda, se excluye $P_{t-1}$‚Äã, cuya matriz de coeficientes no debe ser cero en la ecuaci√≥n de oferta.

-   **Conclusi√≥n**: Si $\det(\beta_2) > 0$, la condici√≥n de rango se satisface.

#### Estimaci√≥n

**M√©todo de MCI**:

1.  **Forma Reducida**:

    -   Demanda: $P_t = \Pi_0 + \Pi_1 I_t + \Pi_2 P_{t-1} + v_t$

    -   Oferta: $Q_t = \Pi_3 + \Pi_4 I_t + \Pi_5 P_{t-1} + v_t$‚Äã

2.  **Aplicaci√≥n de MCO**:

    -   Estimaci√≥n de par√°metros de forma reducida ($\Pi$) usando MCO.

3.  **Coeficientes Estructurales**:

    -   Derivaci√≥n de los coeficientes estructurales a partir de las estimaciones de la forma reducida:

        -   $\Pi_0 = (\beta_0 - \alpha_0) / (\alpha_1 - \beta_1)$

        -   $\Pi_1 = -\alpha_2 / (\alpha_1 - \beta_1)$

        -   $\Pi_2 = \beta_2 / (\alpha_1 - \beta_1)$

**M√©todo de MC2E**:

1.  **Primera Etapa**:

    -   Regresi√≥n de $Y_1$‚Äã (variable end√≥gena) sobre todas las variables predeterminadas ($X_1, X_2, X_3, X_4$) para obtener $\hat{Y}_1$‚Äã:

        -   $Y_1 = \hat{\Pi}_0 + \hat{\Pi}_1 X_1 + \hat{\Pi}_2 X_2 + \hat{\Pi}_3 X_3 + \hat{\Pi}_4 X_4 + \hat{u}_1$‚Äã

2.  **Segunda Etapa**:

    -   Sustituci√≥n de $Y_1$‚Äã por $\hat{Y}_1$‚Äã y aplicar MCO:

        -   $Y_1 = \beta_0 + \beta_{12} \hat{Y}_2 + \gamma_{11} X_1 + \gamma_{12} X_2 + u^*_1$‚Äã

### Tabla de Resumen

| Concepto           | Descripci√≥n                                                 | F√≥rmulas Importantes                                                                                              |
|-------------------------|----------------------|-------------------------|
| **Identificaci√≥n** | Asegura la estimabilidad √∫nica de par√°metros estructurales. | CondicioÀän¬†de¬†Orden: $K‚àík‚â•m‚àí1$                                                                                    |
|                    |                                                             | Condici√≥n de Rango: $det(\text{matriz de excluidas})\neq0$                                                        |
| **M√©todo de MCI**  | Se usa para modelos exactamente identificados.              | Paso 1: Forma reducida: $$P_t = \Pi_0 + \Pi_1 I_t + \Pi_2 P_{t-1} + v_t$$                                         |
|                    |                                                             | Paso 2: MCO en forma reducida: $$\beta = (X^T X)^{-1} X^T Y$$                                                     |
|                    |                                                             | Paso 3: Coeficientes estructurales: $$\Pi = f(\alpha, \beta)$$                                                    |
| **M√©todo de MC2E** | Se usa para ecuaciones sobreidentificadas.                  | Paso 1: $$Y_1 = \hat{\Pi}_0 + \hat{\Pi}_1 X_1 + \hat{\Pi}_2 X_2 + \hat{\Pi}_3 X_3 + \hat{\Pi}_4 X_4 + \hat{u}_1$$‚Äã |
|                    |                                                             | Paso 2: $$Y_1 = \beta_0 + \beta_{12} \hat{Y}_2 + \gamma_{11} X_1 + \gamma_{12} X_2 + u^*_1$$                      |

## Modelo de Vectores Autorregresivos (VAR)

Un modelo de vectores autorregresivos (VAR) es un tipo de modelo estad√≠stico utilizado para analizar la relaci√≥n entre m√∫ltiples series temporales. En lugar de modelar cada serie temporal por separado, como se har√≠a en un modelo univariado, un VAR modela simult√°neamente todas las series temporales en un sistema.

La idea fundamental detr√°s de un VAR es que cada variable en el sistema se regresa a s√≠ misma en funci√≥n de sus valores pasados, as√≠ como de los valores pasados de las otras variables en el sistema. Esto significa que cada variable en el sistema se modela como una funci√≥n lineal de sus propios rezagos (valores pasados) y de los rezagos de todas las dem√°s variables.

Por ejemplo, consideremos un sistema con dos series temporales: el PIB y la tasa de desempleo. Un modelo VAR para este sistema podr√≠a modelar tanto el PIB como la tasa de desempleo en funci√≥n de sus valores pasados y de los valores pasados de la otra variable. Esto permitir√≠a analizar c√≥mo el PIB y la tasa de desempleo afectan mutuamente entre s√≠ a lo largo del tiempo.

Veamos el modelo estructural din√°mico [modelo (1)]:

$$y_{1t}= \alpha_{10} + \alpha_{11}y_{2t} + \alpha_{12}y_{1t-1} + \alpha_{13}y_{2t-1} + \gamma^{¬¥}_1z_t +\epsilon_1t$$

$$y_{2t}= \alpha_{20} + \alpha_{21}y_{1t} + \alpha_{22}y_{1t-1} + \alpha_{23}y_{2t-1} + \gamma^{¬¥}_2z_t +\epsilon_2t$$

Donde $y_{1t}$ , $y_{2t}$ son **variables estacionarias**, y $\epsilon_{1t}$ , $\epsilon_{2t}$ son procesos ruido blanco con esperanza cero y varianzas $\sigma^{2}_{\epsilon_{1t}}$, $\sigma^{2}_{\epsilon_{2t}}$ y covarianza $\sigma_{12}$.

El modelo (1) es de ecuaciones simult√°neas con **dos variables end√≥genas** $y_{1t}$ y $y_{2t}$ y un vector $z_t$ de **variables ex√≥genas**.

Un *shock* sobre $y_{2t}$, en la forma de un valor no nulo de la **innovaci√≥n** estructural $\epsilon_{2t}$, afecta directamente a $y_{2t}$, pero tambi√©n influye a $y_{1t}$ a trav√©s de la presencia de $y_{2t}$ como variable explicativa en la primera ecuaci√≥n.

Adem√°s, este **efecto se propaga en el tiempo**, debido a la presencia de los valores rezagados de ambas variables como variables explicativas.

Las variables explicativas ex√≥genas $z_t$ **tambi√©n pueden aparecer con rezagos en el modelo**. Por ejemplo, $z_t$ podr√≠a ser una tendencia determinista o que recoja la estacionalidad.¬†$z_t$¬†tambi√©n puede representar variables tal que¬†$E(z_{t‚àís}{~}\epsilon_{1t})=ùê∏(z_{ùë°-s} ~ \epsilon_{2ùë°})=0¬†~ ‚àÄ_ùë†$. Por ejemplo, el precio de barril de petr√≥leo que se determina en mercados internacionales mientras¬†$y_{1t}$ y $y_{2t}$ son variables de la macroeconm√≠a que se determinan en la economia interna.

Ahora, el Modelo (1) se puede representar de forma matricial de la siguiente forma:

$$\Pi y_t = \Gamma_0 + \Gamma_1 y_{t-1} + \Phi z_t + \varepsilon_t$$

Donde:

$$\Pi = \begin{equation}\begin{pmatrix}1 & -\alpha_{11} \\-\alpha_{21} & 1 \end{pmatrix}\end{equation}$$ , $\Gamma_0 =\begin{equation}\begin{pmatrix} \alpha_{10} \\\alpha_{20} \end{pmatrix}\end{equation}$ , $\Gamma_1 = \begin{equation}\begin{pmatrix} \alpha_{12} & \alpha_{13} \\\alpha_{22} & \alpha_{23} \end{pmatrix}\end{equation}$ , $\Phi =\begin{equation}\begin{pmatrix} \gamma_{1} \\\gamma_{2} \end{pmatrix}\end{equation}$

Este modelo se conoce como *VAR estructural* y presenta dos problemas:

1.  la simultaneidad, al aparecer cada una de las dos variables como variable explicativa en la ecuaci√≥n de la otra, lo que genera inconsistencia del estimador MCO, podr√≠a resolverse estimando por variables instrumentales, siempre que contemos con instrumentos adecuados, lo cual no es sencillo de justificar. Adem√°s, el segundo problema podr√≠a persistir.

2.  si los t√©rminos de error tuviesen autocorrelaci√≥n, las estimaciones MCO ser√≠an inconsistentes, al tratarse de un modelo din√°mico se resuelve tratando de ampliar la estructura din√°mica del modelo hasta lograr que los t√©rminos de error carezcan de autocorrelaci√≥n.

Supongamos que la matriz $\Pi$ tiene inversa $det(\Pi) \neq~ 0$ , tenemos entonces:

$$y_t = \Pi^{-1} \Gamma_0 + \Pi^{-1}\Gamma_1 y_{t-1} + \Pi^{-1}\Phi z_t + \Pi^{-1} \varepsilon_t$$

$$y_t = \Pi^{-1} \Gamma_0 + \Pi^{-1}\Gamma_1 y_{t-1} + \Pi^{-1}\Phi z_t + \Pi^{-1} \varepsilon_t$$

$$y_t = \textbf{A}_0 + \textbf{A}_1 y_{t-1} + \textbf{M} z_t + u_t$$

Donde:

$$\textbf{A}_0 = \Pi^{-1} \Gamma_0$$ , $$\textbf{A}_1 = \Pi^{-1}\Gamma_1$$ , $$\textbf{M} = \Pi^{-1}\Phi$$ , $$u_t = \Pi^{-1} \varepsilon_t$$

Asi, hemos obtenido en modelo de forma reducida o **modelo vectorial autoregresivo**¬†(VAR) en el cual:

$y_{1t}= \beta_{10} + \beta_{11}y_{1t-1} + \beta_{12}y_{2t-1} + \textbf{m}_{11}z_t + u_{1t}$

$y_{2t}= \beta_{20} + \beta_{21}y_{1t-1} + \beta_{22}y_{2t-1} + \textbf{m}_{21}z_t + u_{2t}$

Este seria un modelo VAR de orden n en su forma reducida:

$$y_{1t}= \beta_{10} + \sum_{j=1}^{k}\beta_{j}y_{t-j} + \sum_{j=1}^{k}\textbf{m}_{j}z_{t-j} + u_{1t}$$

$$y_{2t}= \beta_{20} + \sum_{j=1}^{k}\theta_{j}y_{t-j} + \sum_{j=1}^{k}\textbf{m}_{j}z_t + u_{2t}$$

En la forma reducida de un modelo VAR (Modelo de Vectores Autorregresivos), las ecuaciones se expresan en t√©rminos de las variables end√≥genas del sistema en funci√≥n de sus rezagos y, posiblemente, variables ex√≥genas. La estructura de un modelo VAR en su forma reducida se puede describir de la siguiente manera:

1.  **Variables End√≥genas**: Estas son las variables que se est√°n modelando en el sistema. Por ejemplo, si estamos modelando el PIB, la inflaci√≥n y la tasa de inter√©s, estas ser√≠an nuestras variables end√≥genas.

2.  **Rezagos**: Cada variable end√≥gena se expresa como una funci√≥n lineal de sus propios rezagos y de los rezagos de las otras variables end√≥genas en el sistema. Por ejemplo, la variable end√≥gena $y_{1t}$ en el rezago $j$ se puede expresar como $y_{t-j}$‚Äã.

3.  **Variables Ex√≥genas (opcional)**: Adem√°s de las variables end√≥genas, el modelo VAR en su forma reducida puede incluir variables ex√≥genas que no est√°n determinadas dentro del sistema, pero que pueden afectar a las variables end√≥genas. Estas variables pueden incluir datos econ√≥micos, pol√≠ticos o cualquier otro factor relevante.

4.  **Par√°metros del Modelo**: Los par√°metros del modelo son los coeficientes que multiplican a los rezagos de las variables end√≥genas y, posiblemente, a las variables ex√≥genas. Estos par√°metros son estimados a partir de los datos y capturan la relaci√≥n entre las diferentes variables en el sistema.

5.  **Error T√©rmino (Residuos)**: El t√©rmino de error en la forma reducida del modelo VAR captura la parte de la variabilidad de las variables end√≥genas que no es explicada por los t√©rminos autoregresivos y las variables ex√≥genas. Estos errores se suponen que son independientes e id√©nticamente distribuidos, con una distribuci√≥n normal. donde las $u$ son los terminos de error estoc√°tico, llamados impulsos, innovaciones o choques en el lenguaje VAR.

6.  La utilizacion de muchas o muy pocas variables rezagadas puede conducir a un problema de consumo de muchos grados de libertad, la aparicion de la multicolinealidad o errores de especificacion. una forma de decidir esta cuesti√≥n es utilizar criterios como el de Akaike o el de Schwarz, para decidir el modelo que proporcione los valores mas bajo de estos.

7.  El**orden de los modelos VAR est√° dado por el n√∫mero de rezagos**que se usa en cada ecuaci√≥n. El modelo descrito anteriormente es entonces un $\textbf{VAR(1)}$, para denotar tambi√©n el n√∫mero de variables se usa$\textbf{VAR}_{2}(1)$

### Criterios de Informaci√≥n

Un problema central en el an√°lisis de modelos VAR es encontrar el n√∫mero de rezagos que produce los mejores resultados. La comparaci√≥n de modelos generalmente se basa en criterios de informaci√≥n como el Akaike `AIC`, Bayesiano `BIC` o Hannan-Quinn `HQ`, buscando que se minimice el valor del criterio de informaci√≥n.

$$AIC=\frac{‚àí2} lT + \frac 2pT$$

$$BIC=\frac {‚àí2}lT+ \frac {2ln(T)}T$$

$$HQ=\frac {‚àí2}lT + \frac {2kln(ln(T))}T$$

Donde $l=\frac {‚àíTk}{2}(1+ln(2œÄ))‚àí\frac T2ln(|Œ£|)$, y $p=k(d+nk)$ el n√∫mero de par√°metros estimados en el modelo VAR, siendo $d$ es el n√∫mero de variables ex√≥genas, $n$ el orden del VAR, $k$ el n√∫mero de variables end√≥genas.

Por lo general, el `AIC` es preferible a otros criterios, debido a sus caracter√≠sticas favorables de pron√≥stico de muestras peque√±as. El `BIC` y `HQ`, sin embargo, funcionan bien en muestras grandes y tienen la ventaja de ser un estimador consistente, es decir, converge a los valores verdaderos.

### Funciones de Impulso Respuesta

Las funciones de impulso-respuesta (IRF) son una herramienta importante en el an√°lisis de modelos VAR (Vector Autoregressive). Proporcionan informaci√≥n sobre c√≥mo las variables en un sistema responden a los cambios en otras variables a lo largo del tiempo, espec√≠ficamente en respuesta a un "impulso" o un shock en una de las variables.

Aqu√≠ hay una explicaci√≥n detallada de las funciones de impulso-respuesta en modelos VAR:

1.  **Definici√≥n de Impulso-Respuesta**: En un modelo VAR, el t√©rmino "impulso" se refiere a un choque o shock que afecta a una de las variables del sistema. La funci√≥n de impulso-respuesta describe c√≥mo las otras variables del sistema responden a este impulso en el tiempo.

2.  **C√°lculo de las IRF**: Las IRF se calculan mediante simulaci√≥n. Una vez estimado el modelo VAR, se introduce un impulso unitario (o un impulso en el nivel deseado) en una de las variables del sistema y se observa c√≥mo las otras variables responden a este impulso a lo largo de m√∫ltiples per√≠odos de tiempo.

3.  **Interpretaci√≥n de las IRF**: Las IRF muestran c√≥mo un cambio en una variable afecta a otras variables en el sistema a lo largo del tiempo. Una IRF t√≠picamente muestra c√≥mo la variable end√≥gena (o variable de respuesta) responde al impulso en una variable ex√≥gena (o variable de impulso) en diferentes horizontes temporales.

4.  **Propiedades de las IRF**:

    -   **Direcci√≥n y Magnitud de la Respuesta**: Las IRF muestran si las variables responden positiva o negativamente al impulso, as√≠ como la magnitud de esa respuesta.

    -   **Persistencia**: Las IRF tambi√©n indican si el efecto del impulso persiste en el tiempo o disminuye gradualmente.

    -   **Efectos Cruzados**: Las IRF muestran c√≥mo los diferentes impulsos afectan a las variables en el sistema, lo que puede ayudar a entender las interacciones entre las variables.

5.  **Utilidad de las IRF**: Las IRF son √∫tiles para evaluar el impacto de diferentes pol√≠ticas o choques en una econom√≠a, comprender las din√°micas de las variables en un sistema econ√≥mico y pronosticar el comportamiento futuro de las variables en funci√≥n de cambios en otras variables.

### Tipos de Funcion de Impulso Respuesta

En un modelo VAR (Vector Autoregression), se pueden calcular dos tipos de funciones de impulso respuesta:

1.  Funciones de impulso respuesta al impulso unitario: Estas funciones muestran c√≥mo las variables responden a un shock de una desviaci√≥n est√°ndar en una variable espec√≠fica en un periodo de tiempo y c√≥mo se propagan esos efectos a lo largo de los periodos siguientes. Es decir, muestran el impacto de un shock de una magnitud espec√≠fica en una variable sobre las dem√°s variables en el modelo.

2.  Funciones de impulso respuesta acumuladas: Estas funciones muestran la respuesta acumulada de las variables a lo largo del tiempo despu√©s de un shock en una variable espec√≠fica. Muestran c√≥mo se acumulan los efectos de un shock en una variable sobre las dem√°s variables en el modelo a lo largo de varios periodos.

Ambos tipos de funciones de impulso respuesta son √∫tiles para analizar c√≥mo se propagan los efectos de un shock en una variable a lo largo del tiempo y c√≥mo afecta a las dem√°s variables en el modelo VAR. Esto permite comprender mejor las interacciones entre las variables y predecir c√≥mo se comportar√°n en respuesta a cambios en una de ellas.

### Causalidad de Granger

La causalidad de Granger es un concepto importante en el an√°lisis de series temporales que se utiliza para determinar si una serie temporal proporciona informaci√≥n √∫til para predecir otra serie temporal. Es una herramienta com√∫nmente utilizada en el contexto de los modelos VAR (Vector Autoregressive).

Aqu√≠ est√° una explicaci√≥n detallada de la causalidad de Granger en el contexto de los modelos VAR:

1.  **Definici√≥n**: La causalidad de Granger establece que una serie temporal $y_{1t}$ "Granger-causa" a otra serie temporal $y_{2t}$ si la informaci√≥n pasada de $y_{1t}$ ayuda a predecir $y_{2t}$ mejor que solo utilizando la informaci√≥n pasada de $y_{2t}$.

2.  **Principio**: Si la serie $y_{1t}$ Granger-causa a la serie $y_{2t}$, entonces los rezagos de $y_{1t}$ se incluir√°n como predictores en el modelo para predecir $y_{2t}$. En otras palabras, los rezagos de $y_{1t}$ tienen un poder predictivo significativo para $y_{2t}$.

3.  **Prueba de Causalidad de Granger**: La causalidad de Granger se eval√∫a mediante una prueba estad√≠stica. En el contexto de los modelos VAR, esta prueba implica ajustar dos modelos:

    -   Modelo restringido: Un modelo VAR que solo incluye rezagos de la serie $y_{2t}$ como predictores para predecir $y_{2t}$.

    -   Modelo no restringido: Un modelo VAR que incluye rezagos tanto de la serie $y_{2t}$ como de la serie $y_{1t}$como predictores para predecir $y_{2t}$.

4.  **Comparaci√≥n de Modelos**: Despu√©s de ajustar ambos modelos, se utiliza una prueba estad√≠stica (se utiliza la estadisticaF) para comparar su ajuste. Si el modelo no restringido (que incluye rezagos de $y_{1t}$ ) se ajusta significativamente mejor que el modelo restringido (que no incluye los rezagos de $y_{1t}$), entonces se concluye que la serie $y_{1t}$ Granger-causa a la serie $y_{2t}$.

5.  **Interpretaci√≥n**: Si se establece que la serie $y_{1t}$ Granger-causa a la serie $y_{2t}$, significa que la informaci√≥n pasada de $y_{1t}$ contiene informaci√≥n adicional que ayuda a predecir $y_{2t}$, m√°s all√° de lo que ya se puede predecir con la informaci√≥n pasada de $y_{2t}$.

**Causalidad de Granger**: $y_{1t}$ granger causa $y_{2t}$ si un modelo que usa valores actuales $y_{2t}$ pasados de $y_{1t}$ y valores actuales y pasados de $y_{2t}$ para predecir valores futuros de $y_{2t}$ tiene un error de pron√≥stico menor que un modelo que solo usa valores actuales y pasados de $y_{2t}$ para predecir $y_{2t}$. En otras palabras, la causalidad de Granger responde a la siguiente pregunta: **¬øayuda el pasado de la variable** $y_{1t}$ a mejorar la predicci√≥n de los valores futuros de $y_{2t}$?

**Causalidad instant√°nea**: $y_{1t}$ causa $y_{2t}$ (en el sentido de Granger instant√°neo) si un modelo que usa valores actuales, pasados y futuros de $y_{1t}$ y valores actuales y pasados de $y_{2t}$ para predecir $y_{2t}$ tiene un error de pron√≥stico menor que un modelo que solo usa valores actuales y pasados de $y_{1t}$ y valores actuales y valores pasados de $y_{2t}$. En otras palabras, la causalidad instant√°nea de Granger responde a la pregunta: **¬øconocer el futuro de** $y_{1t}$ me ayuda a predecir mejor el futuro de $y_{2t}$? Si s√© que va a hacer $y_{1t}$, ¬øme ayuda a saber lo que va a saber $y_{2t}$?

### Tabla Resumen

| Concepto                           | Descripci√≥n                                                                                                                                                                         |
|------------------------|------------------------------------------------|
| **Modelo VAR**                     | Modelo que analiza la relaci√≥n entre m√∫ltiples series temporales simult√°neamente, modelando cada variable en funci√≥n de sus valores pasados y los de otras variables en el sistema. |
| **Estructura Matricial**           | $$y_t = \Gamma_0 + \Gamma_1 y_{t-1} + \Phi z_t + \varepsilon_t$$                                                                                                                    |
| **Matrices del Modelo**            | $\Gamma_0, \Gamma_1, \Phi$‚Äã derivadas de las ecuaciones individuales.                                                                                                                |
| **Forma Reducida del VAR**         | $$y_t = \textbf{A}_0 + \textbf{A}_1 y_{t-1} + \textbf{M} z_t + u_t$$                                                                                                                |
| **Problemas en VAR**               | Simultaneidad (inconsistencia del MCO), autocorrelaci√≥n (inconsistencia de estimaciones MCO).                                                                                       |
| **Criterios de Informaci√≥n**       | **AIC:** Mejor para muestras peque√±as. **BIC y HQ:** Mejores para muestras grandes. F√≥rmulas espec√≠ficas para cada criterio.                                                        |
| **Funciones de Impulso-Respuesta** | Muestran c√≥mo las variables responden a choques en otras variables a lo largo del tiempo.                                                                                           |
| **Causalidad de Granger**          | Determina si una serie temporal proporciona informaci√≥n √∫til para predecir otra. **Prueba de Causalidad:** Comparaci√≥n entre modelos restringidos y no restringidos.                |
| **Errores y Soluciones**           | Simultaneidad resuelta con variables instrumentales. Autocorrelaci√≥n resuelta ampliando la estructura din√°mica.                                                                     |

## **Modelo Heteroced√°stico Condicional Autorregresivo (ARCH)**

el Modelo Heteroced√°stico Condicional Autorregresivo (ARCH) es un modelo utilizado en econometr√≠a y finanzas para modelar la volatilidad de series temporales. Fue introducido por Robert F. Engle en 1982 y es particularmente √∫til para capturar la heterocedasticidad condicional en los datos financieros, donde la variabilidad puede cambiar con el tiempo.

### **Conceptos Clave del Modelo ARCH**

1.  **Heterocedasticidad Condicional:** La varianza de los errores no es constante a lo largo del tiempo, sino que depende de los errores pasados. En un contexto financiero, esto significa que los periodos de alta volatilidad tienden a ser seguidos por periodos de alta volatilidad, y lo mismo ocurre para los periodos de baja volatilidad.

2.  **Autorregresividad de la Varianza:** La varianza condicional de los errores en un momento dado se modela como una funci√≥n lineal de los errores pasados.

### **Especificaci√≥n del Modelo ARCH(p)**

El modelo ARCH(p) (donde $p$ denota el n√∫mero de retardos incluidos) se especifica de la siguiente manera:

1.  **Modelo de Media:** Primero, se especifica el modelo para la serie temporal $y_t$‚Äã. Esto puede ser un modelo simple de media o un modelo ARMA, por ejemplo:

    $y_{t} = \mu + \epsilon_{t}$

    donde $\epsilon_{t}$ son los errores (residuos) del modelo de media, y $\mu$ es la media del proceso.

2.  **Modelo de Varianza Condicional:** La varianza condicional de los errores $\epsilon_{t}$ se modela como una funci√≥n de los errores pasados:

    $\sigma_{t}^{2} = \alpha_{0} + \alpha_{1}\epsilon_{t-1}^{2} + \alpha_{2}\epsilon_{t-2}^{2} + ... + \alpha_{p}\epsilon_{t-p}^{2}$ ‚Äã

    donde:

    -   $\sigma_{t}^{2}$ es la varianza condicional en el tiempo $t$.

    -   $\alpha_{0} > 0$ es una constante.

    -   $\alpha_{i} ‚â• 0$ son los coeficientes que miden el impacto de los errores pasados en la varianza condicional.

3.  **Errores:** Los errores $\epsilon_{t}$ se suponen que son ruido blanco con media cero y varianza condicional $\sigma_{t}^{2}$ :

    $\epsilon_{t} \sim \textbf{N}(0, \sigma_{t}^{2})$

### **Estimaci√≥n del Modelo ARCH**

La estimaci√≥n del modelo ARCH generalmente implica los siguientes pasos:

1.  **Estimar el Modelo de Media:** Ajustar el modelo de media (por ejemplo, un modelo ARMA) y obtener los residuos $\epsilon_{t}$‚Äã.

2.  **Estimaci√≥n de la Varianza Condicional:** Ajustar el modelo de varianza condicional ARCH(p) a los residuos al cuadrado $\epsilon_{t}^{2}$ ‚Äã utilizando t√©cnicas de m√°xima verosimilitud.

3.  **Evaluaci√≥n del Modelo:** Verificar si los residuos del modelo ARCH muestran las caracter√≠sticas esperadas (por ejemplo, verificar que los residuos estandarizados son ruido blanco).

### **Ejemplo de Aplicaci√≥n**

Supongamos que queremos modelar la volatilidad de los retornos diarios de una acci√≥n. Podr√≠amos especificar un modelo ARCH(1) de la siguiente manera:

1.  **Modelo de Media:** $y_{t} = \mu + \epsilon_{t}$

2.  **Modelo ARCH(1):** $\sigma_{t}^{2} = \alpha_{0} + \alpha_{1}\epsilon_{t-1}^{2}$

Aqu√≠, la varianza condicional $\sigma_{t}^{2}$‚Äã en el tiempo $t$ depende linealmente del cuadrado del error en el tiempo $t-1$. Si $\alpha_{1}$‚Äã es significativo, indica que hay dependencia en la volatilidad de los retornos.

### **Limitaciones del Modelo ARCH**

-   **Simplicidad:** Los modelos ARCH pueden ser demasiado simples para capturar todas las caracter√≠sticas de la volatilidad en series temporales financieras.

-   **N√∫mero de Par√°metros:** A medida que $p$ aumenta, el n√∫mero de par√°metros a estimar tambi√©n aumenta, lo que puede complicar la estimaci√≥n y la interpretaci√≥n.

### **Extensiones**

Para superar algunas de las limitaciones del modelo ARCH, se han desarrollado extensiones como el modelo GARCH (Generalizaci√≥n ARCH), que incluye tanto retardos de los errores como retardos de las varianzas pasadas.

### **Resumen**

El modelo ARCH es una herramienta poderosa para modelar la heterocedasticidad condicional en series temporales, permitiendo capturar la naturaleza cambiante de la volatilidad en los datos financieros. Espec√≠ficamente, la varianza de los errores se modela como una funci√≥n de los errores pasados, proporcionando una forma de capturar la agrupaci√≥n de volatilidad observada en muchas series temporales financieras.

## **Modelo Heteroced√°stico Condicional Autorregresivo Generalizado (GARCH)**

El Modelo Heteroced√°stico Condicional Autorregresivo Generalizado (GARCH) es una extensi√≥n del modelo ARCH que captura la variabilidad temporal en la volatilidad de una serie temporal. Fue introducido por Tim Bollerslev en 1986. El modelo GARCH es ampliamente utilizado en finanzas y econometr√≠a para modelar series temporales financieras, donde la volatilidad puede cambiar con el tiempo.

### **Conceptos Clave del Modelo GARCH**

1.  **Heterocedasticidad Condicional:** La varianza de los errores en una serie temporal no es constante a lo largo del tiempo, sino que depende de los errores y varianzas pasadas.

2.  **Autorregresividad en la Varianza:** La varianza condicional de los errores depende de los errores pasados y de las varianzas condicionales pasadas, proporcionando una estructura m√°s completa y flexible que el modelo ARCH.

### **Especificaci√≥n del Modelo GARCH(p, q)**

El modelo GARCH(p, q) se especifica de la siguiente manera:

1.  **Modelo de Media:** Primero, se especifica el modelo para la serie temporal $y_{t}$:

    $y_{t} = \mu + \epsilon_{t}$

    donde $\epsilon_{t}$‚Äã son los errores (residuos) del modelo de media, y $\mu$ es la media del proceso.

2.  **Modelo de Varianza Condicional:** La varianza condicional $\sigma_{t}^{2}$‚Äã se modela como una funci√≥n lineal de los errores pasados y de las varianzas condicionales pasadas:

    $\sigma_{t}^{2} = \alpha_{0} + \sum_{i=1}^{q} \alpha_{i}\epsilon_{t-i}^{2} + \sum_{j=1}^{p} \beta_{j}\sigma_{t-j}^{2}$

    donde:

    -   $\sigma_{t}^{2}$‚Äã es la varianza condicional en el tiempo $t$.

    -   $\alpha_{0} > 0$ es una constante.

    -   $\alpha_{i} ‚â• 0$ son los coeficientes que miden el impacto de los errores pasados al cuadrado.

    -   $\beta_{j} ‚â• 0$ son los coeficientes que miden el impacto de las varianzas condicionales pasadas.

### **Estimaci√≥n del Modelo GARCH**

La estimaci√≥n del modelo GARCH generalmente implica los siguientes pasos:

1.  **Estimar el Modelo de Media:** Ajustar el modelo de media (por ejemplo, un modelo ARMA) y obtener los residuos $\epsilon_{t}$‚Äã.

2.  **Estimaci√≥n de la Varianza Condicional:** Ajustar el modelo de varianza condicional GARCH(p, q) a los residuos al cuadrado $\epsilon_{t}^{2}$‚Äã utilizando t√©cnicas de m√°xima verosimilitud.

3.  **Evaluaci√≥n del Modelo:** Verificar si los residuos del modelo GARCH muestran las caracter√≠sticas esperadas (por ejemplo, verificar que los residuos estandarizados son ruido blanco).

### **Ejemplo de Aplicaci√≥n**

Supongamos que queremos modelar la volatilidad de los retornos diarios de una acci√≥n. Podr√≠amos especificar un modelo GARCH(1, 1) de la siguiente manera:

1.  **Modelo de Media:** $y_{t} = \mu + \epsilon_{t}$‚Äã

2.  **Modelo GARCH(1, 1):** $\sigma_{t}^{2} = \alpha_{0} + \alpha_{1}\epsilon_{t-1}^{2} + \beta_{1}\sigma_{t-1}^{2}$

Aqu√≠, la varianza condicional $\sigma_{t}^{2}$ en el tiempo $t$ depende linealmente del cuadrado del error en el tiempo $t‚àí1$ y de la varianza condicional en el tiempo $t‚àí1$. Este modelo captura tanto la memoria corta (a trav√©s de $\epsilon_{t-1}^{2}$ ) como la memoria larga (a trav√©s de $\sigma_{t-1}^{2}$) de la volatilidad.

### **Ventajas del Modelo GARCH**

-   **Flexibilidad:** Al incluir tanto errores pasados como varianzas pasadas, el modelo GARCH puede capturar de manera m√°s efectiva la din√°mica de la volatilidad en los datos financieros.

-   **Aplicabilidad:** Los modelos GARCH son aplicables a una amplia variedad de series temporales financieras, incluyendo precios de acciones, tasas de cambio y tasas de inter√©s.

### **Limitaciones del Modelo GARCH**

-   **Complejidad:** La estimaci√≥n de modelos GARCH puede ser compleja y computacionalmente intensiva, especialmente para valores altos de $p$ y $q$.

-   **Suposici√≥n de Normalidad:** La suposici√≥n de que los errores estandarizados son normales puede no ser realista en todos los casos. Existen extensiones como GARCH-T que permiten distribuciones alternativas para los errores.

### **Resumen**

El modelo GARCH es una herramienta poderosa para modelar la volatilidad condicional en series temporales financieras. Extiende el modelo ARCH al incluir tanto errores pasados como varianzas pasadas, lo que permite capturar la naturaleza persistente de la volatilidad en los datos. Es ampliamente utilizado en econometr√≠a y finanzas para prever la volatilidad y gestionar el riesgo.

### **Pruebas, Estimaciones y Pron√≥sticos**

La prueba del multiplicador de Lagrange (LM) es una herramienta estad√≠stica utilizada para detectar la presencia de efectos ARCH en una serie temporal. Los efectos ARCH se refieren a la situaci√≥n en la que la varianza de los errores no es constante a lo largo del tiempo, sino que depende de los errores pasados.

A continuaci√≥n, se describe el procedimiento para llevar a cabo una prueba LM para efectos ARCH:

### **Procedimiento de la Prueba LM para Efectos ARCH**

1.  **Estimar un Modelo de Regresi√≥n B√°sico:** Primero, estima el modelo de regresi√≥n b√°sico, que podr√≠a ser un modelo ARIMA o cualquier otro modelo de serie temporal adecuado. Obt√©n los residuos de este modelo.

    $y_{t}= \beta X_{t} + \epsilon_{t}$

    Aqu√≠, $y_{t}$‚Äã es la variable dependiente, $X_{t}$ son las variables independientes, $\beta$ son los coeficientes del modelo, y $\epsilon_{t}$‚Äã son los residuos.

2.  **Cuadrar los Residuos:** Calcula los residuos al cuadrado $(e_{t}^{2})$ . Estos valores se usar√°n para detectar la heterocedasticidad.

3.  **Regresi√≥n Auxiliar:** Realiza una regresi√≥n auxiliar donde los residuos cuadrados se regresan sobre $q$ retardos de los mismos residuos cuadrados.

    $e_{t}^{2}=\alpha_{0} + \alpha_{1}e_{t-1}^{2}+\alpha_{2}e_{t-2}^{2} + ... + \alpha_{q}e_{t-q}^{2} + v_{t}$

    Aqu√≠, $\alpha_{0}$ es el intercepto, $\alpha_{i}$ son los coeficientes de los residuos retardados, y $v_{t}$ es el t√©rmino de error de esta regresi√≥n auxiliar.

4.  **Calcular el Estad√≠stico de Prueba:** El estad√≠stico de prueba LM se calcula como $\textbf{T*R}^{2}$, donde $\textbf{T}$es el n√∫mero de observaciones y $\textbf{R}^{2}$ es el coeficiente de determinaci√≥n de la regresi√≥n auxiliar.

    $\textbf{LM}=\textbf{T*R}^{2}$

5.  **Distribuci√≥n Asint√≥tica:** Bajo la hip√≥tesis nula de que no hay efectos ARCH (es decir, todos los $\alpha_{i}=0$, el estad√≠stico LM sigue una distribuci√≥n chi-cuadrado $\textbf{X}^{2}$ con $q$ grados de libertad.

6.  **Decisi√≥n:** Compara el estad√≠stico LM con el valor cr√≠tico de la distribuci√≥n $\textbf{X}^{2}$ con $q$ grados de libertad. Si el estad√≠stico LM es mayor que el valor cr√≠tico, se rechaza la hip√≥tesis nula, indicando la presencia de efectos ARCH. De lo contrario, no se rechaza la hip√≥tesis nula.

### **Resumen**

La prueba del multiplicador de Lagrange (LM) para efectos ARCH sigue estos pasos principales:

1.  Estimar el modelo b√°sico y obtener los residuos.

2.  Calcular los residuos al cuadrado.

3.  Realizar una regresi√≥n auxiliar de los residuos cuadrados sobre $q$ retardos de los mismos.

4.  Calcular el estad√≠stico $\textbf{T*R}^{2}$.

5.  Comparar el estad√≠stico con la distribuci√≥n chi-cuadrado para tomar la decisi√≥n.

Esta prueba es una herramienta efectiva para detectar heterocedasticidad condicional en las series temporales, y es ampliamente utilizada en econometr√≠a y finanzas para modelar y prever la volatilidad.

## **¬øQue son los Errores Estandarizados?**

Los errores estandarizados son una forma de normalizar los residuos de un modelo para hacerlos comparables a lo largo del tiempo y evaluar su comportamiento de una manera m√°s uniforme. En el contexto de modelos de heterocedasticidad condicional como GARCH, los errores estandarizados son particularmente √∫tiles para verificar la adecuaci√≥n del modelo y la presencia de heterocedasticidad residual.

### **Definici√≥n de Errores Estandarizados**

Para una serie temporal $y_{t}$‚Äã modelada con un modelo de media y un modelo de varianza condicional (como un GARCH), los errores estandarizados se calculan de la siguiente manera:

1.  **Errores del Modelo** $(\epsilon_{t})$‚Äã: Estos son los residuos del modelo, que se obtienen como la diferencia entre los valores observados y los valores ajustados por el modelo de media: $\epsilon_{t} = y_{t} -  \hat y_{t}$ ‚Äã donde $\hat y_{t}$ es el valor ajustado.

2.  **Varianza Condicional** $(\sigma_{t}^{2})$: Esta es la varianza condicional estimada en cada punto en el tiempo, que se obtiene del modelo de varianza condicional (por ejemplo, GARCH): $(\sigma_{t}^{2})$‚Äã

3.  **Errores Estandarizados** $(e_{t})$ : Los errores estandarizados se obtienen dividiendo los errores del modelo por la ra√≠z cuadrada de la varianza condicional: $e_{t} = \frac{\epsilon_{t}} {\sigma_{t}}$ ‚Äã‚Äã donde $\sigma_{t} = \sqrt{\sigma_{t}^{2}}$‚Äã es la desviaci√≥n est√°ndar condicional.

### **Interpretaci√≥n y Uso**

Los errores estandarizados $e_{t}$‚Äã tienen una media esperada de cero y una varianza esperada de uno, siempre y cuando el modelo est√© correctamente especificado. Esto permite comparar los errores a lo largo del tiempo y verificar si hay patrones que indiquen una mala especificaci√≥n del modelo.

### **Evaluaci√≥n del Modelo con Errores Estandarizados**

1.  **An√°lisis de Ruido Blanco:** Los errores estandarizados deben comportarse como ruido blanco, es decir, deben ser independientes e id√©nticamente distribuidos con media cero y varianza uno. Si no se comportan de esta manera, podr√≠a indicar que el modelo no ha capturado adecuadamente la din√°mica de la serie temporal.

2.  **Gr√°ficos de Errores Estandarizados:** Los gr√°ficos de los errores estandarizados pueden ayudar a identificar patrones o anomal√≠as en los residuos que no fueron capturados por el modelo. Por ejemplo, si los errores estandarizados muestran agrupaciones de valores altos o bajos, puede ser un signo de que hay heterocedasticidad residual no modelada.

3.  **Pruebas Estad√≠sticas:** Pruebas estad√≠sticas, como la prueba de Ljung-Box, pueden ser aplicadas a los errores estandarizados para verificar la presencia de autocorrelaci√≥n. Tambi√©n se pueden usar pruebas para la normalidad de los errores estandarizados, como la prueba de Jarque-Bera.

### **Ejemplo Pr√°ctico**

Supongamos que hemos ajustado un modelo GARCH(1,1) a una serie temporal de retornos financieros:

1.  **Estimaci√≥n del Modelo:** Ajustamos el modelo y obtenemos los residuos $\epsilon_{t}$.

2.  **C√°lculo de la Varianza Condicional:** Estimamos la varianza condicional $\sigma_{t}^{2}$ utilizando los par√°metros del modelo GARCH.

3.  **C√°lculo de los Errores Estandarizados:** Dividimos cada residuo $\epsilon_{t}$ por la desviaci√≥n est√°ndar condicional $\sigma_{t}$‚Äã: $e_{t} = \frac{\epsilon_{t}} {\sigma_{t}}$

4.  **Evaluaci√≥n:** Analizamos los errores estandarizados $e_{t}$‚Äã para verificar si son ruido blanco y si siguen una distribuci√≥n normal.

### **Resumen**

Los errores estandarizados son una herramienta clave para evaluar la adecuaci√≥n de los modelos de series temporales con heterocedasticidad condicional. Al normalizar los errores, permiten una evaluaci√≥n uniforme de los residuos a lo largo del tiempo y ayudan a identificar posibles problemas de especificaci√≥n del modelo.

## Identificaci√≥n

La mejor herramienta de identificaci√≥n puede ser un gr√°fico de la serie de tiempo. Por lo general, es f√°cil detectar periodos de mayor variaci√≥n esparcidos a lo largo de la serie.

Puede resultar √∫til examinar el ACF y el PACF de $\epsilon_{t}$ y $\epsilon_{t}^{2}$. Por ejemplo,

-   si $\epsilon_{t}$ parece ser ruido blanco y parece ser $ùê¥ùëÖ(1)$, se sugiere un modelo $ARCH(1)$ para la varianza.

-   Si el PACF de sugiere $AR(p)$, entonces $ARCH(m)$ puede funcionar.

Los modelos $GARCH$ pueden ser sugeridos por una estructura de tipo ARMA en el ACF y PACF de $\epsilon_{t}^{2}$.

En la pr√°ctica, es posible que tengas que experimentar con varias estructuras ARCH y GARCH despu√©s de detectar que es necesario aborar el problema con este tipo de modelos.

# **Modelo de Panel de Datos**

Los modelos de panel de datos son una t√©cnica econom√©trica que se utiliza para analizar datos que tienen tanto una dimensi√≥n temporal (series de tiempo) como una dimensi√≥n transversal. Es decir, estos modelos trabajan con datos que se recogen para varios individuos (como personas, empresas, pa√≠ses, etc.) a lo largo del tiempo. Este tipo de datos tambi√©n se conoce como datos longitudinales o datos de panel

## **Caracter√≠sticas y Ventajas de los Datos del Panel**

Dimensi√≥n Temporal y Transversal : Los datos de panel permiten analizar el comportamiento de los individuos a lo largo del tiempo, lo que proporciona informaci√≥n tanto sobre diferencias entre individuos (dimensi√≥n transversal) como sobre cambios dentro de los individuos a lo largo del tiempo (dimensi√≥n temporal).

Control de Heterogeneidad : Permiten controlar la heterogeneidad no observada, es decir, las caracter√≠sticas no observables que pueden influir en las variables de inter√©s y que no cambian con el tiempo para cada individuo.

Mejora de la Eficiencia : Incrementan la eficiencia de las estimaciones econom√©tricas al proporcionar m√°s informaci√≥n y reducir la colinealidad entre variables.

al estudiar la secci√≥n transversal repetida de observaciones, los datos de panel resulta mas adecuado para estudiar la dinamica de cambio.

Con datos de panel tenemos N individuos observados en varios periodos consecutivos, asi:

$$Y_{it} = \beta_{1} + \beta_{2}X_{2it} + \beta_{3}X_{3it} + \epsilon_{t}$$

Donde:

-   $Y_{it}$ = valor de $Y$ para el individuo $i$ en el periodo $t$.

-   $i$ = es la i-√©sima unidad transversal

-   $t$ = es el tiempo

-   $X$ = son la variables independientes, que en un principios no se suponen estocasticas

El termino de error cumple con las suposiciones clasicas $\epsilon_{t} \sim \textbf{N}(0, \sigma_{t}^{2})$

Nota 1: se supone que hay un maximo de N unidades transversales u observaciones, y un maximo de T periodos.

Nota 2: si cada unidad tranversal tiene el mismo el mismo n√∫mero de observaciones de series de tiempo, entonces dicho panel (de datos) se llama panel balanceado . Si el n√∫mero de observaciones difiere entre los miembros del panel se dice que es un panel desbalanceado

Nota 3: existen otras fomas de clasificaci√≥n de los datos de panel.

macropaneles: los individuso son paises, sectores, regiones. N es peque√±os respecto a T. (N \> T) o (T \> N)

micropaneles: los individuos son personal u hogares. N es mucho mas grande que T

# **El modelo de panel de datos agrupado**

Es una t√©cnica de an√°lisis econom√©trico utilizada cuando se tienen datos que combinan aspectos de series temporales y datos de corte transversal, pero sin distinguir entre diferentes entidades (individuos, empresas, pa√≠ses, etc.) en t√©rminos de interceptos espec√≠ficos. En este modelo, se asume que las diferencias entre las entidades no son significativas o que no es necesario modelarlas expl√≠citamente.

## **Caracter√≠sticas del Modelo de Panel de Datos Agrupado:**

### **Intercepci√≥n Com√∫n**:

Asume que todas las entidades en el panel tienen el mismo intercepto. No se controla por diferencias espec√≠ficas entre entidades.

### **Homogeneidad**:

Se considera que todas las entidades son homog√©neas en cuanto a las variables explicativas y su relaci√≥n con la variable dependiente.

### **Simplificaci√≥n**:

La especificaci√≥n del modelo es m√°s simple en comparaci√≥n con los modelos de efectos fijos y aleatorios, ya que no incorpora interceptos o efectos espec√≠ficos de cada entidad.

### **Formulaci√≥n del Modelo**:

El modelo de panel de datos agrupado se puede representar de la siguiente manera:

$$Y_{it}=\alpha + \beta X_{it} + \epsilon_{it}$$‚Äã

Donde:

-   $Y_{it}$ es la variable dependiente para la entidad $i$ en el tiempo $t$.

-   $\alpha$ es el intercepto com√∫n para todas las entidades.

-   $\beta$ es un vector de coeficientes que mide el efecto de las variables explicativas.

-   $X_{it}$‚Äã es un vector fila de variables explicativas para la entidad $i$ en el tiempo $t$.

-   $\epsilon_{it}$ es el t√©rmino de error.

Nota: los parametrso estimados del modelo son validos para todos los individuos en todos los peridos de tiempo.

## **Supuestos del Modelo de Panel de Datos Agrupados**:

### **Homogeneidad de los Interceptos**:

Supuesto: Se asume que todas las entidades tienen el mismo intercepto $(\alpha)$.

Implicaci√≥n: No se consideran diferencias espec√≠ficas entre entidades que podr√≠an influir en la variable dependiente.

### **Linealidad**:

Supuesto: La relaci√≥n entre las variables independientes $(X_{it}‚Äã$) y la variable dependiente $(Y_{it})$ es lineal.

Implicaci√≥n: Se puede modelar mediante una combinaci√≥n lineal de las variables explicativas.

### **Exogeneidad**:

Supuesto: Las variables explicativas $(X_{it}‚Äã)$ no est√°n correlacionadas con el t√©rmino de error $(\epsilon_{it}‚Äã)$.

Implicaci√≥n: $\mathbb{E}(\epsilon_{it} | X_{it}) = 0$. Esto asegura que las variables independientes no est√°n influenciadas por factores inobservables que afectan a la variable dependiente.

### **No Autocorrelaci√≥n**:

Supuesto: Los errores $(\epsilon_{it}‚Äã)$ no est√°n correlacionados a lo largo del tiempo para una misma entidad.

Implicaci√≥n: $\mathbb{E}(\epsilon_{it} \epsilon_{is}) = 0$ para $t \neq s$. Esto significa que no hay relaci√≥n entre los errores en diferentes per√≠odos de tiempo para una misma entidad.

### **No Correlaci√≥n entre Entidades**:

Supuesto: Los errores $(\epsilon_{it})$ de diferentes entidades no est√°n correlacionados.

Implicaci√≥n: $\mathbb{E}(\epsilon_{it} \epsilon_{jt}) = 0$ para $i \neq j$. Esto asegura que no hay dependencia entre los errores de diferentes entidades.

### **Homoscedasticidad**:

Supuesto: La varianza de los errores $(\epsilon_{it}‚Äã$) es constante para todas las observaciones.

Implicaci√≥n: $\text{Var}(\epsilon_{it}) = \sigma^{2}$. Esto significa que la dispersi√≥n de los errores es constante a lo largo del tiempo y entre las entidades.

### **Independencia de las Variables Explicativas**:

Supuesto: Las variables explicativas $(X_{it}‚Äã)$ son independientes entre s√≠.

Implicaci√≥n: No hay multicolinealidad perfecta entre las variables explicativas.

### **Parametro Estimado del Modelo Agrupado**

Para estimar el par√°metro $\beta$, se utiliza la f√≥rmula de M√≠nimos Cuadrados Ordinarios (MCO), que se aplica de la misma manera que en un modelo de regresi√≥n lineal est√°ndar. La f√≥rmula para el estimador de $\beta$ es:

$$\hat{\beta} = (X¬¥ X)^{-1}X¬¥Y$$

Donde:

-   $X$ es la matriz de las variables explicativas, incluyendo todas las observaciones de todas las entidades y per√≠odos de tiempo.

-   $X¬¥$ es la transpuesta de la matriz $X$.

-   $Y$ es el vector de las observaciones de la variable dependiente.

-   $\hat{\beta}$‚Äã es el vector de coeficientes estimados.

Nota: en este caso el modelo de homogeneidad total (modelo agrupado) tendria la siguiente representaci√≥n de la ecuaci√≥n de parametrso estimados

$$\hat{\beta}_{agrupado} = (\sum_{i=1}^{N}\sum_{t=1}^{T}x¬¥_{it}¬†x_{it})^{-1} \sum_{i=1}^{N}\sum_{t=1}^{T}x¬¥_{it} y_{it}$$

## **Ventajas y Desventajas**:

### **Ventajas**:

#### **Simplicidad**:

Es m√°s f√°cil de estimar y entender debido a su simplicidad en comparaci√≥n con los modelos de efectos fijos o aleatorios.

#### **Menos Demandante de Datos**:

Requiere menos datos para estimar, ya que no necesita suficientes observaciones para cada entidad como en los modelos de efectos fijos.

### **Desventajas**:

#### **Ignora Heterogeneidad**:

No controla por la heterogeneidad no observable entre entidades, lo que puede sesgar las estimaciones si las diferencias entre entidades son significativas.

#### **Asunci√≥n Fuerte de Homogeneidad**:

Asume que todas las entidades son id√©nticas en cuanto a su relaci√≥n con las variables explicativas, lo cual puede no ser realista en muchos casos.

### **Ejemplos de Aplicaci√≥n**:

**An√°lisis de Ventas en Diferentes Tiendas**:

Suponiendo que se tiene un panel de datos de ventas de varias tiendas a lo largo del tiempo y se asume que todas las tiendas responden de la misma manera a las estrategias de marketing.

**Estudio del Impacto de Pol√≠ticas Econ√≥micas**:

An√°lisis del impacto de una pol√≠tica econ√≥mica espec√≠fica en varios pa√≠ses, asumiendo que la pol√≠tica tiene el mismo efecto en todos los pa√≠ses.

# **Modelo de Efecto Fijos**

El modelo de efectos fijos en panel de datos se utiliza para controlar por heterogeneidad inobservable que puede variar entre entidades (individuos, empresas, pa√≠ses, etc.) pero no a lo largo del tiempo. Este modelo permite que cada entidad tenga su propio intercepto, capturando as√≠ efectos espec√≠ficos de cada entidad.

-   Nota: entonces, podemos pensar que $COV(X_{it},~\alpha_{i}) \neq 0$. Una posible soluci√≥n es eliminar $\alpha_{i}$. (endogeneidad por variables omitidas)

## **Formulaci√≥n Matem√°tica del Modelo de Efectos Fijos**:

El modelo de efectos fijos se puede escribir de la siguiente manera:

$y_{it} = \alpha_{i} + \beta x_{ it} + \epsilon_{it}$

Donde:

-   $y_{it}$ es la variable dependiente para la entidad $i$ en el tiempo $t$.

-   $\alpha_{i}$ ‚Äã es el intercepto espec√≠fico de la entidad $i$, capturando los efectos fijos.

-   $\beta$ es el vector de coeficientes que mide el efecto de las variables explicativas.

-   $x_{it}$‚Äã es el vector de variables explicativas para la entidad $i$ en el tiempo $t$.

-   $\epsilon_{it}$ es el t√©rmino de error.

### **Eliminaci√≥n de los Efectos Fijos**:

Para estimar el modelo sin tener que estimar directamente cada $\alpha_{i}$‚Äã, se utiliza la transformaci√≥n de "dentro de la entidad"

-   Nota: se quiere eliminar el intercepto espec√≠fico de la entidad $i$, que captura los efectos fijos. Se debe entender que el concepto efectos fijos hace referencia a habilidades propias de cada individuo o entidad, los cuales son inobservable por ser propios de cada individuo o entidad.

### **Calcular la Media Dentro de la Entidad**:

-   $\bar{y}_{i} = \frac{1}{T_{i}}\sum_{t=1}^{T_{i}}y_{it}$

-   $\bar{x}_{i} = \frac{1}{T_{i}}\sum_{t=1}^{T_{i}}x_{it}$‚Äã

ademas,

-   $\bar{\beta}_{0} = \frac{1}{T_{i}}\sum_{t=1}^{T_{i}}\beta_{0} = \frac{1}{T}T\beta_{0} = \beta_{0}$ es una constante si se tuviera un intercepto en comun.

-   $\bar{\alpha}_{i} = \frac{1}{T_{i}}\sum_{t=1}^{T_{i}}\alpha_{i} = \frac{1}{T}T\alpha_{i} = \alpha_{i}$

Donde $T_{i}$‚Äã es el n√∫mero de observaciones de la entidad $i$.

### **Restar las Medias**:

Restamos la media dentro de la entidad de cada observaci√≥n:

$$y_{it} - \bar{y}_{i} = (\alpha_{i} + \beta X_{ it} + \epsilon_{it}) - ( \alpha_{i} + \beta \bar{X}_{i} + \bar{\epsilon}_{i})$$

$$y_{it} - \bar{y}_{i} = (\alpha_{i} - \alpha_{i}) + \beta (X_{ it} - \bar{X}_{i}) + (\epsilon_{it} - \bar{\epsilon}_{i})$$

-   Nota: se elimina $(\alpha_{i} - \alpha_{i})$ y nos queda un modeloque recibe el nombre de transformaci√≥n de efectos fijo

Esto simplifica a:

$$\tilde{y}_{it} = \beta \tilde{x}_{it} + \tilde{\epsilon}_{it}$$‚Äã

Donde:

-   $\tilde{y}_{it} = y_{it} - \bar{y}_{i}$

-   $\tilde{x}_{it} = x_{it} - \bar{x}_{i}$

-   $\tilde{\epsilon}_{it} = \epsilon_{it} - \bar{\epsilon}_{i}$‚Äã

Estimaci√≥n por M√≠nimos Cuadrados Ordinarios (MCO):

El modelo transformado se puede estimar usando M√≠nimos Cuadrados Ordinarios (MCO):

$$\hat{\beta} = (\tilde{X¬¥} \tilde{X})^{-1}\tilde{X¬¥}\tilde{Y}$$

‚ÄãDonde:

-   $\tilde{X}$ es la matriz de las variables explicativas despu√©s de restar las medias dentro de cada entidad.

-   $\tilde{Y}$‚Äã es el vector de la variable dependiente despu√©s de restar las medias dentro de cada entidad.

Nota 1: este modelo explora la variabilidad de $x$ y de $y$ dentro de los individuos a traves del tiempo, donde $\tilde{x}$ y $\tilde{y}$‚Äã son las desviaciones de $y_{it}$ y de $x_{it}$ respecto a su media.

Nota 2: un limitaci√≥n utilizar estimaci√≥n por efectos fijos esta en el hecho de no permitir variables constantes a traves del tiempo.

Nota 3: otra limitaci√≥n es el hecho de obtener estimaciones estadisticamente menos significativas con efectos fijos, ya que la varianza muestral de las variables originales $y_{it}, ~ x_{it},...,x_{ik}$ es mucho mayor que las tranformadas.

Alternativa: Modelo con Dummies

Otra manera de especificar el modelo de efectos fijos es incluyendo variables indicadoras (dummies) para cada entidad:

$$Y_{it} = \alpha +\sum_{i=1}^{N-1} \delta_{i} D_{i} + \beta X_{it} + \epsilon_{it}$$

Donde:

-   $D_{i}$ es una dummy que toma el valor 1 si la observaci√≥n pertenece a la entidad $i$ y 0 en caso contrario.

-   $\delta_{i}$‚Äã captura el efecto fijo de la entidad $i$.

Sin embargo, este enfoque puede ser computacionalmente intensivo si hay muchas entidades.

## **Ejemplo Pr√°ctico**:

Supongamos que tenemos un panel de datos con las siguientes variables:

$y_{it}$: Ingresos de la persona $i$ en el a√±o $t$.

$X_{it}$‚Äã: A√±os de educaci√≥n de la persona $i$ en el a√±o $t$.

Calcular la Media de Ingresos y Educaci√≥n para Cada Persona:

$\bar{y}_{i} = \frac{1}{T_{i}}\sum_{t=1}^{T_{i}}y_{it}$

$\bar{x}_{i} = \frac{1}{T_{i}}\sum_{t=1}^{T_{i}}x_{it}$‚Äã

Restar las Medias:

$\tilde{y}_{it} = y_{it} - \bar{y}_{i}$

$\tilde{X}_{it} = X_{it} - \bar{X}_{i}$‚Äã

Estimar el Modelo Transformado con MCO:

$\hat{\beta} = (\tilde{X¬¥} \tilde{X})^{-1}\tilde{X¬¥}\tilde{Y}$‚Äã

En resumen, el modelo de efectos fijos en panel de datos controla por la heterogeneidad inobservable espec√≠fica de cada entidad, permitiendo estimar los efectos de las variables explicativas de manera m√°s precisa. La transformaci√≥n de "dentro de la entidad" elimina los efectos fijos, facilitando la estimaci√≥n mediante MCO.

# **Efectos Aleatorios**

El modelo de datos de panel de efectos aleatorios es una herramienta estad√≠stica utilizada para analizar datos de panel donde se asume que las diferencias entre unidades (por ejemplo, individuos, empresas, pa√≠ses) pueden ser mejor capturadas por efectos aleatorios en lugar de efectos fijos. Este modelo es adecuado cuando se piensa que los efectos individuales no est√°n correlacionados con las variables explicativas del modelo.

Nota: con efectos fijos queriamos eliminar $\alpha_{i}$ porque creiamos que habia una correlaci√≥n entre $\alpha_{i}$ y alguna de las variables explicativas. Con efectos aleatorios se asume que $COV(X_{it},~\mu_{i}) = 0 ($ $\mu_{i}$ es la variable que em recoge los efectos heterogeneos, es decir, remplazamos $\alpha_{i}$ por $\mu_{i}$ )

## Estructura del Modelo de Efectos Aleatorios

El modelo de efectos aleatorios puede ser formulado matem√°ticamente de la siguiente manera:

$$y_{it} = \alpha + \beta x_{it} + u_{it}$$

Donde:

-   $y_{it}$‚Äã es la variable dependiente para la unidad $i$ en el tiempo $t$.

-   $\alpha$ es el intercepto com√∫n a todas las unidades.

-   $x_{it}$‚Äã es un vector de variables explicativas para la unidad $i$ en el tiempo $t$.

-   $\beta$ es un vector de coeficientes que mide el impacto de las variables explicativas en $y_{it}$‚Äã.

-   $u_{it}$ es el t√©rmino de error compuesto.

El t√©rmino de error compuesto $u_{it}$ se descompone en dos partes:

-   $u_{it} = \mu_{i} + \epsilon_{it}$ ‚Äã

Donde:

-   $\mu_{i}$‚Äã es el efecto aleatorio espec√≠fico de la unidad $i$, que se asume que sigue una distribuci√≥n normal con media cero y varianza $\sigma_{\mu}^{2}$‚Äã. Es decir, $\mu_{i} \sim \mathcal{N}(0, \sigma_{\mu}^{2})$.

-   $\epsilon_{it}$‚Äã es el t√©rmino de error idiosincr√°tico, que tambi√©n se asume que sigue una distribuci√≥n normal con media cero y varianza $\sigma_{\epsilon}^{2}$. Es decir, $\epsilon_{it} \sim \mathcal{N}(0, \sigma_{\epsilon}^{2})$.

## Supuestos del Modelo de Efectos Aleatorios

1.  **No correlaci√≥n entre efectos individuales y variables explicativas**:

    $$\mathbb{E}(\mu_i | x_{it}) = 0$$

    Esto implica que los efectos aleatorios $\mu_{i}$‚Äã no est√°n correlacionados con las variables explicativas $x_{it}$.

2.  **Homocedasticidad**:

    La varianza de los errores idiosincr√°ticos es constante:

    $$\mathbb{E}(\epsilon_{it}^{2}) = \sigma_{\epsilon}^{2}$$

3.  **No autocorrelaci√≥n de los errores idiosincr√°ticos**:

    $$\mathbb{E}(\epsilon_{it} \epsilon_{js}) = 0 \quad \text{para} \quad (i \neq j) \, \text{o} \, (t \neq s)$$

4.  **Distribuci√≥n Normal de los Efectos Aleatorios**:

    $$\mu_i \sim \mathcal{N}(0, \sigma_{\mu}^{2})$$

## Varianza Compuesta del Error

Dado que $u_{it} = \mu_i + \epsilon_{it}$, la varianza total del error puede ser expresada como:

$$\sigma_{u}^{2} = \sigma_{\mu}^{2} + \sigma_{\epsilon}^{2}$$‚Äã

## Estimaci√≥n del Modelo de Efectos Aleatorios

El modelo de efectos aleatorios se estima com√∫nmente utilizando el estimador de m√≠nimos cuadrados generalizados (MCG). El estimador MCG considera la estructura de la varianza-covarianza del error para proporcionar estimaciones eficientes de los coeficientes $\beta$.

veamos: ¬øpodemos calcular los parametros por MCG?

1.  Reescribamos el modelo como: $y_{it} = \alpha + \beta x_{it} + u_{it}$

Donde:

-   $y_{it}$‚Äã es la variable dependiente para la unidad $i$ en el tiempo $t$.

-   $\alpha$ es el intercepto com√∫n a todas las unidades.

-   $x_{it}$‚Äã es un vector de variables explicativas para la unidad $i$ en el tiempo $t$.

-   $\beta$ es un vector de coeficientes que mide el impacto de las variables explicativas en $y_{it}$‚Äã.

-   $u_{it}$ es el t√©rmino de error compuesto. (heterogeneidad no observada + el error idiosincr√°tico)

    Nota: $\epsilon_{it}$ es homocedastico y no esta serialmete correlacionado.

2.  No se conoce el comportamiento de $u_{it}$. Es decir, se tiene que saber si $u_{it}$ esta bien comportada. para esto asumimos que :

    $VAR(\mu_{i}) = \sigma_{\mu_{i}}^{2}$ y $VAR(\epsilon_{i}) = \sigma_{\epsilon_{i}}^{2}$

3.  ¬øc√∫al es la correlaci√≥n intertemporal entre $u_{it}$ y $u_{is}$ $(Corr(u_{it}~ u_{is}))$

    $$\mathbb{Corr}(u_{it}u_{is})= \frac{Cov(u_{it} u_{is})}{\sqrt{VAR(u_{it})VAR(u_{is})}} = \frac{Cov(\mu_{i}+\epsilon_{it}, \mu_{i}+\epsilon_{is})}{\sqrt{[VAR(\mu_{i})+VAR(\epsilon_{it})]^{2}}}$$

    Nota: se expresa la $\mathbb{Corr}(u_{it}u_{is})$ por definici√≥n de correlaci√≥n y se hacemos las sustituciones a partir de las identidades ya halladas.

    $$\mathbb{Corr}(u_{it}u_{is})= \frac{Cov(\mu_i\mu_i) + Cov(\mu_{i} \epsilon_{is}) + Cov(\epsilon_{it}\mu_{i}) + Cov(\epsilon_{it}\epsilon_{is})}{\sigma_{\mu}^{2} + \sigma_{\epsilon}^{2}}$$

Donde: $Cov(\mu_{i} \epsilon_{is}) = 0$, $Cov(\epsilon_{it}\mu_{i})=0$, $Cov(\epsilon_{it}\epsilon_{is}) = 0$

A partir de loa naterior se llega a:

$\mathbb{Corr}(u_{it}u_{is}) = \frac{\sigma_{\mu}^{2}}{\sigma_{\mu}^2 + \sigma_\epsilon^2}$ , es decir $u_{it}$ esta serialmente correlacionado

4.  Filtro de transformaci√≥n

Una transformaci√≥n com√∫nmente usada en el modelo de efectos aleatorios es la deglaci√≥n de los efectos individuales mediante el factor $\theta$, donde:

‚Äã‚Äã$$\theta = 1 - \sqrt{\frac{\sigma_\epsilon^2}{\sigma_\mu^2 + \sigma_\epsilon^2}}$$

Nota: efectos aleatorios corrige esa correlacion serial por medio de $\theta$ .

Aplicando esta transformaci√≥n:

$$y_{it} - \theta \bar{y}_{i} = \alpha(1 - \theta) + \beta (x_{it} - \theta \bar{x}_{i}) + (u_{it} - \theta \bar{u}_{i})$$

Donde $\bar{y}_{i}$ y $\bar{x}_{i}$ son las medias de $y_{it}$‚Äã y $x_{it}$‚Äã a trav√©s del tiempo para la unidad $i$.

Nota 1: la presencia de $\alpha_{i}$ se suaviza por medio de $(1-\theta)$. a medida que $\theta$ se va caercando a 1, la expresi√≥n $(1-\theta)$ se va haciendo cero, por lo que $\mu_{i}$ se va a desaparecer.

Nota 2: el parametro $\theta$ nunca es conocido en la practica porque depende de variables poblacionales, pero es facil de estimar. los software estadisticos implementan esta formula de forma inmediata.

$$\hat{\theta} = 1 - \{\frac{1}{[1 +\frac{T \hat{\sigma}_{\mu}^{2}}{\hat{\sigma}_{\epsilon}^{2}}]}\}$$

**Prueba de Breusch-Pagan Multiplicador de Lagrange (LM) para Efectos Aleatorios en Datos de Panel**

La Prueba de Breusch-Pagan LM se utiliza para determinar la presencia de efectos aleatorios en datos de panel. Se analiza la varianza de los residuos para detectar efectos individuales espec√≠ficos no observables.

La Prueba de Breusch-Pagan LM se utiliza para detectar efectos aleatorios en datos de panel mediante el an√°lisis de la varianza de los residuos. Esto permite determinar si existen efectos individuales espec√≠ficos no observables.

**Pasos Clave:**

1.  **Modelo de Datos de Panel:** Relaciona una variable dependiente con variables explicativas y un t√©rmino de error descompuesto en efectos individuales y errores idiosincr√°ticos.

2.  **Hip√≥tesis de la Prueba:**

    -   **Nula:** No hay efectos aleatorios ($\sigma_{\mu}^2 = 0$).

    -   **Alternativa:** Hay efectos aleatorios ($\sigma_{\mu}^2 > 0$).

3.  **Proceso de Prueba:**

    -   Estimar el modelo de efectos comunes.

    -   Calcular las sumas de residuos cuadrados agrupados y dentro de los grupos.

    -   Comparar el estad√≠stico LM con la distribuci√≥n chi-cuadrado para determinar la presencia de efectos aleatorios.

**Interpretaci√≥n:** Si el estad√≠stico LM es mayor que el valor cr√≠tico de la chi-cuadrado, se rechaza la hip√≥tesis nula, indicando la presencia de efectos aleatorios en los datos de panel.

**Interpretaci√≥n del Resultado**

El estad√≠stico LM sigue una distribuci√≥n chi-cuadrado ($\chi^{2}$) con grados de libertad igual al n√∫mero de par√°metros en el modelo (excluyendo la constante). Si el valor del estad√≠stico LM es mayor que el valor cr√≠tico de la distribuci√≥n chi-cuadrado para un nivel de significancia dado (por ejemplo, 0.05), se rechaza la hip√≥tesis nula, indicando la presencia de efectos aleatorios en los datos de panel.

## Resumen

El modelo de efectos aleatorios es apropiado cuando se puede asumir que las diferencias no observadas entre las unidades del panel son no correlacionadas con las variables explicativas. Este modelo permite una estimaci√≥n m√°s eficiente al aprovechar la variabilidad tanto entre unidades como dentro de las unidades en el tiempo.

Nota 1: efctos aleatorios es consistente, pero no insesgado para $N \longrightarrow \infty$ y $T$ fijo (datos para muchos individuos en un tiempo muy corto)

Nota 2: en el caso donde $T \longrightarrow \infty$ y $N$ fijo no se sabe si efectos aleatorios es consistente. (en este caso es mejor pensar en un metodo de series de tiempo).

Nota 3: volviendo al modelo transformado se tiene:

$$y_{it} - \theta \bar{y}_{i} = \alpha(1 - \theta) + \beta (x_{it} - \theta \bar{x}_{i}) + (u_{it} - \theta \bar{u}_{i})$$

-   si $\theta = 0$ se tiene MCO agrupados (no existe una correlaci√≥n serial)

-   si $0 < \theta < 1$ se tiene efectos aleatorios (existe correlaci√≥n serial)

-   si $\theta =1$ se tiene efectos fijos. (nos da la transformaci√≥n de efectos fijos)

Nota: sabemos que el $\theta$ se remplaza por $\hat{\theta}$ por la imposibilidad de calcular el primero.
